docno="lists-009-1176020"
received="Fri Dec 16 12:58:30 1994"
isoreceived="19941216175830"
sent="Fri, 16 Dec 1994 12:57:06 PST"
isosent="19941216205706"
name="Larry Masinter"
email="masinter@parc.xerox.com"
subject="Re: MIME and binary transport"
id="94Dec16.125712pst.2760@golden.parc.xerox.com"
inreplyto="9412162013.AA11694&#64;acetes.pa.dec.com"
expires="1"

To:mogul@pa.dec.com
Cc:Albert-Lunde@nwu.edu,http-wg%cuckoo.hpl.hp.com@hplb.hpl.hp.com


I used to be on the other side of the fence (I thought scanning for
boundaries was going to be too expensive), but Ned Freed convinced me.
Now I'm a convert. Boundary scanning is also more *reliable* than
content-length, because length calculations are unreliable.

> I was responding to Mitra's point that if you don't use some sort of
> encoding on the data, a file could conceivably contain
> <CR><LF>--boundary--<CR><LF> (or whatever else you wanted to use).  I can
> envision a situation where you couldn't download httpd using http because
> the file contained the boundary string.  Using content-length to determine
> the end of a document would be 100% reliable, since the actual content
> couldn't possibly conflict with the protocol information.

I only require 99.99999% reliability. (Besides, I'm in the market for
a Pentium.)



