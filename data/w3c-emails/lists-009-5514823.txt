docno="lists-009-5514823"
received="Tue Jul 25 13:14:18 1995"
isoreceived="19950725171418"
sent="Tue, 25 Jul 95 13:09:42 MDT"
isosent="19950725190942"
name="Jeffrey Mogul"
email="mogul@pa.dec.com"
subject="Re: Proposal: Checksum header or method"
id="9507252009.AA17531@acetes.pa.dec.com"
inreplyto="Pine.SGI.3.91.950725152210.22182B100000&#64;rpc42.gl.umbc.edu"
expires="1"


To:"Mordechai T. Abzug"<mabzug1@gl.umbc.edu>
Cc: HTTP Working Group<http-wg%cuckoo.hpl.hp.com@hplb.hpl.hp.com>

    Simple file length may not suffice, so it would be better to determine
    the checksum.  Although the client could calculate this, it makes more
    sense to do so on the server side, to preserve bandwidth.

The use of a simple checksum might be too prone to false positives.
I'm not an expert on the topic, but apparently people have developed
"fingerprinting" algorithms that have very low probabilities of
mapping two texts to the same value.

I found one citation on the topic:
Rabin, M. O.
"Fingerprinting by Random Polynomials"
Center for Research in Computing Technology
Harvard University
Report TR-15-81, 1981

but I suspect there are others.

-Jeff



