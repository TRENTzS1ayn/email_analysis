docno="lists-010-10843025"
received="Fri Oct 18 06:27:22 1996"
isoreceived="19961018102722"
sent="Fri, 18 Oct 1996 15:19:33 +0200 (MET DST)"
isosent="19961018131933"
name="Anselm Baird_Smith"
email="abaird@www43.inria.fr"
subject="HTTP Log files"
id="199610181319.PAA26713@www43.inria.fr"
inreplyto="01BBBC43.39AA1860&#64;node4.cacheflow.com"
expires="1"


To: Doug Crow<doug_crow@cacheflow.com>
Cc:"http-wg%cuckoo.hpl.hp.com@hplb.hpl.hp.com"<http-wg%cuckoo.hpl.hp.com@hplb.hpl.hp.com>

Doug Crow writes:
 > I have seen where groups are publishing specWeb96 numbers approaching =
 > 1000 URLs per second.  Using the common log file format and assuming an =
 > average entry of 100 bytes this translates to over 8 Gigabytes of data =
 > in a 24 hour period. =20
 > 
 > Given the importance of tracking hit information with respect to =
 > advertising revenue and in some cases user profiling, what are servers =
 > doing with the size of this log information? =20
 > 
 > Is the hit-metering draft that I have seen reference to going to address =
 > this?
 > 
 > Is there a more appropriate forum for a question such as this?

You may consider giving a look to:

http://www.w3.org/pub/WWW/TR/WD-logfile.html

Which propose a smart log file format to deal with the number of write
accesses to the http log.

Anselm.



