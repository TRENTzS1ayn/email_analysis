docno="lists-011-4377176"
received="Thu Jul 17 15:59:41 1997"
isoreceived="19970717195941"
sent="Thu, 17 Jul 1997 15:47:13 0700 (PDT)"
isosent="19970717224713"
name="Gregory J. Woodhouse"
email="gjw@wnetc.com"
subject="Re: STATUS100 Re: Proposed resolution"
id="Pine.BSF.3.96.970717153147.17807C100000@shell3.ba.best.com"
charset="USASCII"
inreplyto="199707172217.SAA27944&#64;rtpmail03.raleigh.ibm.com"
expires="1"

To:rlgray@raleigh.ibm.com
Cc: HTTP Working Group<http-wg%cuckoo.hpl.hp.com@hplb.hpl.hp.com>,http-wg%cuckoo.hpl.hp.com@hplb.hpl.hp.com


Hmm...It seems to me that the only scenario where an extra round trip is
unavoidable is a client which is unwilling to wait for a 100 response but
which wishes to send a chunked PUT or POST. Since both of these features
are new in HTTP/1.1 this seems like it would be a very unusual situation,
and in this case I'm not sure an extra round trip would be such a bad
thing.

To me, it seems like the real problem is that the server has no way of
knowing how much data to expect. Accepting a chunked PUT or POST is an all
or nothing type of commitment. I doubt it's possible in HTTP/1.1, but it
seems to me that the server need to be able to indicate how much data it
is willing to accept and then allow the client to decide whether or not to
attempt to send the request. (A client may not know how much data it has
to send, but it may know that it will not exceed a certain threshold.)

---
Gregory Woodhouse
gjw@wnetc.com    /    http://www.wnetc.com/home.html
If you're going to reinvent the wheel, at least try to come
up with a better one.



