docno="lists-012-14934802"
received="Fri Oct  6 17:44:18 2000"
isoreceived="20001006214418"
sent="Fri, 6 Oct 2000 09:30:53 0700"
isosent="20001006163053"
name="Mark Nottingham"
email="mnot@mnot.net"
subject="Re: Conformance Test for HTTP 1.1"
id="20001006093053.A805@mnot.net"
charset="usascii"
inreplyto="57C6E3244632D411A2F100508BC8079A13136F&#64;juno.interxtechnology.com"
expires="1"

To: Miles Sabin<msabin@cromwellmedia.co.uk>
Cc:http-wg@cuckoo.hpl.hp.com




I think proxies are the biggest target, because they're so hard to implement
correctly, and so much more complex. In my experience, there's a fairly wide
variance in how implementors choose to interpret the spec.

Of course, once you do one for proxies, it's relatively easy to get client
and server test suites out of it.



On Fri, Oct 06, 2000 at 10:24:14AM +0100, Miles Sabin wrote:
> Mark Nottingham wrote,
> > I've lately been considering starting discussion of 
> > development of something within the W3C, as it was involved 
> > in the development of the HTTP, and has an established 
> > history of developing similar tools (although I'm not sure if
> > W3C can formally commit resources).
> >
> > If anyone has any thoughts about this, please share them, 
> > because I'd like to get this moving.
> 
> This sounds like a fine idea (tho', as you say, it's an open
> question whether or not the W3C would be able to commit
> resources).
> 
> Do you have any particular emphasis in mind: server, clients,
> or proxies, or all equal weight on all?
> 
> Cheers,
> 
> 
> Miles
> 
> -- 
> Miles Sabin                       Cromwell Media
> Internet Systems Architect        5/6 Glenthorne Mews
> +44 (0)20 8817 4030               London, W6 0LJ, England
> msabin@cromwellmedia.com          http://www.cromwellmedia.com/
> 

-- 
Mark Nottingham
http://www.mnot.net/



