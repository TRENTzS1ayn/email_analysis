docno="lists-012-15772088"
received="Thu Nov 30 14:20:42 2000"
isoreceived="20001130192042"
sent="Thu, 30 Nov 2000 09:16:47 0500"
isosent="20001130141647"
name="Scott Lawrence"
email="lawrence@agranat.com"
subject="Re: Http overhead"
id="3A26614F.6050406@agranat.com"
charset="usascii"
inreplyto="852569A7.004BE238.00&#64;ngw2.hns.com"
expires="1"


To:http-wg@cuckoo.hpl.hp.com
CC:dillon@hns.com, Patrik Carlsson<patrik.x.carlsson@era.ericsson.se>

dillon@hns.com wrote:

> 
> 
>      You have an HTTP response header (around 250 bytes) which goes
> in its own segment and then all succeeding data is sent in TCP segments as a
> stream of bytes.
> No overhead other than the TCP/IP overhead.
> 
>      The latest standard (HTTP 1.1) has provisions for compression and "chunked"
> transfers
> which change this, but I haven't seen these used in any real-world situations
> yet.

Chunked encoding is frequently used in situations where the server 
might not know the size of the response body at the time it is 
generating headers.  This is often the case for CGI and other 
dynamic interfaces.

If chunked encoding is used, there is a short chunk header that 
preceeds each chunk - no more than 10 bytes; the chunk size is up to 
the server, but is typically either the record size of the buffer it 
is using to read the dynamic content, or the buffer size of its 
network buffers (depending on which memory it is optimizing for).


-- 
Scott Lawrence      Architect            lawrence@agranat.com
Virata       Embedded Web Technology    http://www.emweb.com/



