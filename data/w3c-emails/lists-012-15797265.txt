docno="lists-012-15797265"
received="Thu Nov 30 18:23:02 2000"
isoreceived="20001130232302"
sent="Thu, 30 Nov 2000 10:11:39 0800"
isosent="20001130181139"
name="Mark Nottingham"
email="mnot@mnot.net"
subject="Re: Http overhead"
id="20001130101138.A21990@mnot.net"
charset="usascii"
inreplyto="852569A7.004BE238.00&#64;ngw2.hns.com"
expires="1"

To:dillon@hns.com
Cc: Patrik Carlsson<patrik.x.carlsson@era.ericsson.se>,http-wg@cuckoo.hpl.hp.com




Almost all modern browsers support content-encoding (gzip, for example), and
most servers can be pummelled into serving compressed content; actually,
I've seen a lot of activity around this recently, with vendors releasing
products to faclilitate compression on the server, or to move it to an
intermediary. 

While not many Web sites are using compression, the number is growing, and
I've heard rumors of some Big sites playing with it on home pages, etc.
(haven't checked recently).

I've also heard rumors that browsers are starting to support
transfer-encoding.


<plug>see http://www.mnot.net/cgi_buffer/</plug>



On Thu, Nov 30, 2000 at 08:47:08AM -0500, dillon@hns.com wrote:
> 
> 
> 
>      You have an HTTP response header (around 250 bytes) which goes in its
> own segment and then all succeeding data is sent in TCP segments as a
> stream of bytes. No overhead other than the TCP/IP overhead.
> 
>      The latest standard (HTTP 1.1) has provisions for compression and
> "chunked" transfers which change this, but I haven't seen these used in
> any real-world situations yet.
> 
>      Doug...................
> 
> 

-- 
Mark Nottingham
http://www.mnot.net/



