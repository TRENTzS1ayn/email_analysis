docno="lists-013-4308613"
received="Tue May  6 17:12:39 2003"
isoreceived="20030506211239"
sent="Tue, 06 May 2003 14:12:32 0700"
isosent="20030506211232"
name="Jeffrey Mogul"
email="Jeff.Mogul@hp.com"
subject="Re: Use hash to reduce traffic"
id="200305062112.h46LCWVn007403@wera.hpl.hp.com"
inreplyto="3EB7B591.182B2549&#64;oracle.com"
expires="1"


To: Diwakar Shetty<diwakar.shetty@oracle.com>
Cc:ietf-http-wg@w3.org


Diwakar Shetty <diwakar.shetty@oracle.com> writes:

    Dont we have "Modified-Since" and "Etags" to do this job already ?
    What will "hash" do extra which is not being done currently by the
    above mentioned two mechanisms ??

The existing mechanisms don't solve the problem of "aliasing" where
two different URLs point to the same content, and a related problem
where a given URL yields content in a sequence like

A
B
C
A

These two effects can cause redundant content transfer (that is,
a hypothetical perfect cache could avoid these transfers).
We found that these two effects together, in one large trace,
caused about 36% of the bytes transferred to be "redundant" in
this sense.  See the WWW 2002 paper I've already cited.

-Jeff



