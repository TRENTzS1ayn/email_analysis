docno="lists-015-11643068"
received="Mon Sep 22 09:14:45 2003"
isoreceived="20030922131445"
sent="Mon, 22 Sep 2003 13:07:17 0000"
isosent="20030922130717"
name="Jim Ley"
email="jim@jibbering.com"
subject="Re: The Return of &quot;WaSP Asks the W3C&quot;"
id="00d501c3810a$7391fff0$428f9bd9@Snork"
charset="iso-88591"
inreplyto="001301c38105$71df8740$6501a8c0&#64;w3c40upc3ma3j2"
expires="1"


To:<public-evangelist@w3.org>


"Richard Ishida" <ishida@w3.org>
> I use XHTML 1.0 exclusively for my web pages these days.  I serve them
> as text/html and follow the compatability suggestions in App C of the
> xhtml spec.

What QA tool do you use to ensure this, is it purely visual inspection, and
human processing, or do you actually have tools that do it for you?

The majority of your reasons are about authoring, and there are good reasons
for authoring in a semantically rich XML format, however authoring and
publishing are seperate activities.  For me XHTML doesn't meet my authoring
needs, it's semantically pretty empty, and applicable only to certain types
of documents.  However even if it meets your authoring needs, that doesn't
follow that is how you should publish it to html user agents, conversion
from XHTML or other XML formats is a simple mechanical process available
from tools such as tidy, as part of your publishing process you can perform
this translation, so you get your authoring ease combined with serving
appropriate content to all users (rather than content which is only
compatible with some html user agents)

> [3] I figure that if we continue to use HTML then browser developers
> will have less incentive to implement xhtml properly.  I'd eventually
> like to be able to use xhtml strict served as application/xhtml+xml, but
> why would browser developers feel motivated to enable that if everyone
> just continues to use html?

My problem with this,  XHTML 2.0, it's a very different mark-up language,
yet as far as I've seen the mime-type will still be application/xhtml+xml,
the current preponderance of invalid XHTML being served as text/html with
the intention that it will be changed to being served as
application/xhtml+xml is a problem for this, as soon as UA's start being
application/xhtml+xml user agents exist, people will change the mime-type
and the UA manufacturers will have to start adding tag-soup parsing of it
too.

For me, xhtml as text/html is a demonstration of how UA manufacturers can
ensure maximum future compatibility by parsing everything as tag-soup - it
supports tag-soup parsing, and far from being a transitional process leading
to a more compliant world, it's rubber stamping the current tag-soup
behaviour.

Encouraging application/xhtml+xml support will be done by serving
application/xhtml , not serving tag-soup, serving tag-soup encourages
tag-soup!

> **  There is one tweak I have to make.  If I want my pages to trigger
> standards-compliant mode in IE I have to remove the xml declaration
> before posting.

I don't particularly understand this, as Appendix C clearly says that you
shouldn't include an xml declaration in any case "Be aware that processing
instructions are rendered on some user agents" (due to a great many browsers
actually rendering it, quite apart from those that change rendering modes
based on it)

Jim.



