docno="lists-015-12287598"
received="Fri Mar  5 03:58:28 2004"
isoreceived="20040305085828"
sent="Fri, 5 Mar 2004 08:55:19 0000"
isosent="20040305085519"
name="Brian Kelly"
email="B.Kelly@ukoln.ac.uk"
subject="RE: The use of W3C standards in Denmark Part II"
id="10403050858.aa05475@lamin.ukoln.ac.uk"
charset="usascii"
inreplyto="000001c4023a$30ad77d0$0300000a&#64;ae35"
expires="1"

To: 'Soren Johannessen'<hal@ae35-unit.dk>,public-evangelist@w3.org



I have had a discussion with Soren directly about similar work I have been
involved in.

I have been analysing Further Education college Web sites on a regional
basis -the most recent surveys are available at
http://www.ukoln.ac.uk/web-focus/events/workshops/rsc-yorkshire-2004/surveys
/

Like Soren, the most prevalent errors are (i) No DOCTYPE and (2) No
character encoding (if there is one, it often defines a Windows character
set.

[I am also finding, in a number of cases, user agent negotiation so that
different pages are served to non-IE browser - in one case (not an FE
college) I found that using Opera I was taken to an accessibility Web site -
and the page did not work :-) ]

As Soren says, even when we try to encourage authors to validate their
pages, they are often confused by the language of the W3C HTML validator.
I'd agree that it would be nice to have a HTML Validator for Dummies tool.

I've also been encouraging deployment of testing tools via a URI interface
(along the lines used on the W3C Web site).  For info on this approach see: 

http://www.ukoln.ac.uk/qa-focus/documents/briefings/briefing-59/

BTW reading Soren's description of her testing methodology, it occurred to
me that we could do with something like EARL to describe the methodology in
a machine-understandable way.

Brian
---------------------------------------
Brian Kelly
UK Web Focus
UKOLN
University of Bath 
BATH
BA2 7AY
Email: B.Kelly@ukoln.ac.uk
Web: http://www.ukoln.ac.uk/
Phone: 01225 383943
FOAF: http://www.ukoln.ac.uk/ukoln/staff/b.kelly/foaf/bkelly-foaf.xrdf
For info on FOAF see http://www.ukoln.ac.uk/ukoln/staff/b.kelly/foaf/ 

> -----Original Message-----
> From: public-evangelist-request@w3.org 
> [mailto:public-evangelist-request@w3.org] On Behalf Of Soren 
> Johannessen
> Sent: 04 March 2004 22:44
> To: public-evangelist@w3.org
> Subject: The use of W3C standards in Denmark Part II
> 
> 
> 
> 
> 
> 2004-03-04: I have got a request for telling more about my survey. In
> 2002 the Danish computer magazine "Computerworld" made a 
> survey about how many governmental/national/municipal 
> authorities did follow the W3C Standards (HTML/XHTML) the 
> survey shows that time only 13 % did follow the W3C 
> Standards. The Danish Ministry for Science, Technology and 
> Innovation strongly encourage W3C Standards since 1997. It's 
> not a law (more a recomandation), but by following the W3C 
> Standards all the Danish citizens could benefits the access 
> to information hosted at the authorities (libraries, schools, 
> etc) by following W3C Standards. That was on of the major 
> reason why use W3C Standards in the public sector. I decided 
> in January 2004 to follow up on this survey from 2002 and 
> make a new one. My survey now shows that 3,05 % of 2033 home 
> pages was valid according W3C Validator.
> 
> I am going to tell more about the method to collect the 
> information from
> 2033 authorities' home pages. To find all these home pages in 
> Denmark, the Danish Ministry for Science, Technology and 
> Innovation have a online list of them. 
> http://bpn.surveyonline.dk/stat/statalfa.jsp Then I just 
> started from the first until the last one. Some of the home 
> pages on the list does not exit any more. I made a 
> spreadsheet to insert data from all the 2033 home pages.
> 
> How I made a testing - I did use Microsoft Internet Explorer 
> 6.0 as browser. When I visit a home page I did the following 
> thing. "View
> >Source" options so I was sure that I got the main entrance 
> page and not
> a Frame (did't use the right click -view source- options by 
> the mouse).
> When the raw source text file was open, I was looking after a 
> DOCTYPE-Declaration in the top of the document. If no DOCTYPE 
> then the test was finish because W3C Validator can't parse 
> without a DOCTYPE. The home page without a DOCTYPE was 
> consider as non valid. If there were a DOCTYPE the W3C 
> Validator was used. I did only test the main entrance page. 
> It's good indicator how the rest of the sub-pages are 
> regarding W3C standards. I assume, that webmasters has spend 
> most time on the page main entrance page . They have been 
> reading about webdesign guidelines etc.,  before the main 
> entrance page has been publish live for the public audience. 
> The data from the survey was collected during January 31th 
> until February 16th 2004..
> 
> I provide you all with an option to download the survey data 
> in a spreadsheet, I have translated the name of the columns 
> You can download it from 
> http://www.ae35-unit.dk/standard/englishw3ctest.xls (420 
> KB)it's in Microsoft Excel format. )
> 
> There are 8 columns in the spreadsheet
> 
> 1) Name of the home page
> 2) The testing URL
> 3) Any DOCTYPE? (Yes or No options. If no then I did't use 
> W3C Validator because never will parse any documents without 
> a DOCTYPE)
> 4) Which DOCTYPE? (I have manual from each home page copy and 
> pasted the DOCTYPE into the spreadsheet. You will find some 
> creative ways of writting it, like some webmasters think that 
> "EN" stands for english and then they have translated it to 
> danish "DA" A lot also forget the 2nd line of the DOCTYPE 
> like ""http://www.w3.org/TR/html4/loose.dtd" W3C Validator 
> can still parse the document even the 2nd line is missing.
> 5) Did home pages with a DOCTYPE manage the test at W3C 
> Validator (Yes or No)
> 6) Encoding problems (for home pages with problems here it's 
> marked in the cell with Encoding problems)
> 7) Number of errors (how many errors did W3C Validator found)
> 8) Webserver tool (I have use the Web-sniffer 
> http://web-sniffer.net/ to detect the webserver and also to 
> check the encoding labelling (iso-8859-1, UTF-8 etc) from the 
> HTTP Response Header (Note Content-Type for text/html is not 
> in the spreadsheet only the webserver tool)
> 
> 
> Note: it's only a snap-shot of the day I tested the home-page 
> things can have changed. One more thing I can figure out is 
> that when 10 % of the home pages use HTML 3.2 or HTML 2.0 in 
> their DOCTYPE it's a direct way to have many errors according 
> W3C Validator. Education in this matter is also needed. The 
> main entrance page is a dynamic page and change quite often 
> so using old HTML version is a bad idea, I don't think 
> webmasters is thinking about this issues.
> 
> 
> After finding out that 64,8 % is missing the DOCTYPE. I 
> decided to create a minor guide in Danish for this issue. 
> Since missing character encoding labeling (iso-8859-1, UTF-8) 
> is also a major problem. I decided to explain very simple 
> about this.  I have also give webmaster a chance to begin on 
> Unicode (UTF-8), by given them a links to a Danish "how to 
> use Unicode on webpages" however I fell in this matter in 
> Denmark, more education is needed. Often at small authorities 
> home page maybe the webeditor is only working 2-3 hours pr 
> week she/he has other things to do at work. Unicode can be a 
> little bit complex to understand. Since many is using 
> webeditor software like DreamWeaver, Frontpage etc, they 
> never see the HTML code, they just write and then publish.  
> FrontPage is pr default inserting "Windows-1252"in the 
> META-TAG. My advice for Danish Ministry for Science, 
> Technology and Innovation was that in this issue, high-tech 
> people have to create templates for not so HTML/XHTML 
> familiar workers like the example I gave above. Second 
> advice, high tech people have to set up systems that use 
> PHP/ASP server side scripting language, CMS etc. to use a 
> correct W3C Standard template. We can't assume or demand that 
> every one that produce text/content for the web knows things 
> like this.
> 
> During my survey I have also the purpose explain how the W3C 
> validator works, the W3C validator is a cool tool if you 
> understand the errors messages. For not so good english 
> reading people(webmasters) it's very difficult to figure out 
> the "Character encoding label" error etc. Well we need a 
> Danish localized version. Maybe an idea for W3C to create 
> localized versions for more countries in the world? 
> (HTML-TIDY maybe also?)The local goverments around the world 
> could pay for a localized version then W3C would hosted these 
> versions. It's would benefit a lot of not so HTML/XHTML skilled people
> 
> Well my main ambition with this survey is to create a debate 
> in Denmark.
> So politicians begin react. One big problem I also see is 
> that the retailer of CMS never ever tells/educate the buyers, 
> how to set up the HTML/XHTML template for correct W3C 
> standard. Lot's of people in public sector thinks, well we 
> have bought this expensive CMS then we also assume that 
> everything is fine, but that's not the case. 
> 
> Finally, I don't think the problems above are only a problem 
> in Denmark.
> I think it's world wide problem. 
> 
> Hope you can use the data to something and got the major points above.
> Please feel free to ask me again. After publising my survey 
> 2004-02-28, there has not been to much respons in the danish 
> media yet. I have e-mail newspapers etc. But no one yet have 
> publish anything.
> Soren Johannessen
> 
> 
> Major findings from survey at
> http://www.ae35-unit.dk/standard/english.html
> 
> 



