docno="lists-017-13166780"
received="Wed Apr 21 03:50:21 2004"
isoreceived="20040421075021"
sent="Wed, 21 Apr 2004 09:50:05 +0200"
isosent="20040421075005"
name="Dominique Haza?lMassieux"
email="dom@w3.org"
subject="Re: [meeting] extra Action Item - 2004-0420"
id="1082533804.9760.158.camel@stratustier"
charset="iso-885915"
inreplyto="D8A0C331-9337-11D8-8B5D000393A63FC8&#64;w3.org"
expires="1"

To: olivier Thereaux<ot@w3.org>
Cc: QA Dev<public-qa-dev@w3.org>


Hi Olivier,

Le mer 21/04/2004 ? 04:01, olivier Thereaux a ?crit :
> On Apr 21, 2004, at 10:55, olivier Thereaux wrote:
> > * 1 - checklink *
> > There is, however, dissent on whether/when the link checker is 
> > actually a robot, and a feeling (for some of us) that following 
> > robots.txt makes it less useful. A first workaround (implemented 
> > during the meeting!) is to add a note explaining how to modify one's 
> > robots.txt to allow the link checker to do more than other agents.
> 
> The note is at:
> http://qa-dev.w3.org/wlc/#bot
> 
> Could I assign you the (extra) action item of taking care of this for 
> the robots.txt at www.w3.org? This would be setting a good example.

Sure, done. FWIW, I couldn't test it as well as I wanted, because my
auth credentials are rejected when trying to checklink e.g. /Projects
(Team-only) ; I'm not sure why they were, nor if that's a known problem
in this instance of the linkchecker (I tried several other password
protected areas without luck).

Dom
-- 
Dominique Haza?l-Massieux - http://www.w3.org/People/Dom/
W3C/ERCIM
mailto:dom@w3.org





