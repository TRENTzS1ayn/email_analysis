docno="lists-017-13942514"
received="Tue Jun  8 18:07:24 2004"
isoreceived="20040608220724"
sent="Wed, 09 Jun 2004 00:06:49 +0200"
isosent="20040608220649"
name="Bjoern Hoehrmann"
email="derhoermi@gmx.net"
subject="Re: checklink: 3.9.3 beta, feedback requests"
id="40cb37de.547133906@smtp.bjoern.hoehrmann.de"
charset="ISO-88591"
inreplyto="1086732060.29458.144.camel&#64;bobcat.mine.nu"
expires="1"

To: Ville Skytt?<ville.skytta@iki.fi>
Cc: QA Dev<public-qa-dev@w3.org>



* Ville Skytt? wrote:
>Regarding the beta announcement, I would like to request feedback in
>particular of the following (feel free to rephrase, comment, and add
>items):
>
>- Robots exclusion standard support in the link checker.  Good or bad?

It would be good to announce in what way it supports it; as discussed,
there are apparently several approaches, like do you read the submitted
document if the robots.txt of that server does not allow it or will it
refuse to check any link in that case (as it does not download anything
but robots.txt). Without such information one would have to figure this
out by testing or looking at the code which is unlikely to yield in
much feedback.



