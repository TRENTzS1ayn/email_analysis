docno="lists-020-11195669"
received="Wed May  5 08:20:44 2004"
isoreceived="20040505122044"
sent="Wed, 5 May 2004 13:20:27 +0100 "
isosent="20040505122027"
name="Seaborne, Andy"
email="andy.seaborne@hp.com"
subject="Various result forms"
id="E864E95CB35C1C46B72FEA0626A2E808028A3407@0-mail-br1.hpl.hp.com"
expires="-1"


To:public-rdf-dawg@w3.org


To try to put requirements 3.2 (Variable Binding Results) and 3.5 (Subgraph
Results) in some kind of context ...

There are a number of result forms that people have used or suggested:  I
know of:

1/ Variable bindings
   Common for the case of get data out of RDF

2/ Result set in RDF
   As 1/ - encoded in RDF

3/ RDF=>XHTML/XML

4/ Subgraph extraction:
   Actually, two forms:
4a/ The query pattern with variables substituted for each
    solutions and result merged.  Reexecuting the query
    gives the same results.
4b/ The triples from the graph that were matched.
    Would include, for example, the subclass resource 
    when asked (?x rdf:type x:superclass).
   
4a == 4b for an RDF graph with no inference processing.

5/ RDF => RDF
   Templating - a generalisation of 4/ where a template (RDF graph with
variables in it) is used to create new RDF at the server.  At the F2F this
was voted against as a requirement.


Getting information out of RDF directly is 1,2,3.  Part of a larger
processing system (distributed) is 4 & 5.


1/ is about the problem of getting information (node and arc labels) out of
RDF; 2/ is A way of recording 1/.  I have used 2/ to give access to query
languages from (other language) toolkits that have no query capability.  I
execute the query remotely (all it takes is to pass a string from
application to server - the client toolkit does not need to understand the
QL) and use the result set format [1] as the transfer syntax.  That's
convenient because the client toolkit can parse and work with the returned
RDF.  Having the client requirements simple can, for small devices, take
many forms - this is one of them.

3/ is important for the display of information directly from RDF sources.
Using XQuery/XSLT/etc looks to be useful (practical, utilizes programmer
skills, builds on existing work, what people expect, ...).

4 & 5 are about getting some RDF out of another (larger, remote) RDF
dataset.  The results would be further manipulated before going to the user,
and that includes passing in on to other machines where the final
destination of user/application is not the one making the query; instead the
extracted subgraph is sent on to other places. This is RDF=>RDF, for
example, passing around RSS entries.  The general requirement is that part
of a large, remote target graph is extracted and deliver for further, local
processing.

For 4/, examples include the "tell me about" queries and the use of the
pattern of query to define the subgraph.  In fact, 4a gives an alternative
way of approaching the example above if the client toolkit does have the QL.
Re-execution is much, much cheaper, essentially as there are so few negative
search branches to follow.

Andy

[1] http://www.w3.org/2003/03/rdfqr-tests/recording-query-results.html



