docno="lists-020-7726971"
received="Thu Mar 18 17:34:23 2004"
isoreceived="20040318223423"
sent="Thu, 18 Mar 2004 15:28:06 -0700"
isosent="20040318222806"
name="Jim Melton"
email="jim.melton@acm.org"
subject="Re: [XSLT 2.0] Data types for a Basic XSLT processor"
id="6.0.0.22.2.20040318152449.02e9a150@gmstimap.oraclecorp.com"
charset="us-ascii"
inreplyto="ltu10mcktq.fsf&#64;colina.demon.co.uk"
expires="-1"


To: Colin Paul Adams<colin@colina.demon.co.uk>
Cc:"Michael Kay"<mhk@mhk.me.uk>,<public-qt-comments@w3c.org>


Colin,

At 07:05 AM 3/18/2004 Thursday, Colin Paul Adams wrote:

> >>>>> "MK" == Michael Kay <mhk@mhk.me.uk> writes:
>
>     MK> It's possible to implement xs:integer using 64-bit hardware
>     MK> arithmetic, I believe*. It's certainly possible to implement
>     MK> it so that it uses hardware arithmetic when the numbers are
>     MK> small enough. I've no idea about xs:decimal - I grew up with
>     MK> machines that did decimal arithmetic in hardware, but I
>     MK> suspect that's gone out of fashion? As for float and double,
>     MK> surely 32-bit floating point is a complete anachronism? 20
>
>Then why is it in XML Schema part 2?

The floating point types in XML Schema part 2 are aligned with, conformant 
to, and based on, IEEE 754.  They were not designed out of whole cloth.


>     MK> But this is aside from the point. I don't believe that numeric
>     MK> arithmetic accounts for a sufficiently high proportion of XSLT
>     MK> execution costs for this to be a real concern.
>
>Then why include xs:double? Pointless.

Er, ah, for better precision?  Because of compatibility with XPath 1.0?


>     MK> 18)". 64 bits is enough to meet this requirement. I think the
>     MK> word "minimum" here is meaningless, and best ignored.
>
>I don't think so. I think it means you should implement arbitrary
>precision if you can.

I disagree (and I attend the Schema meetings, so I have spent at least a 
few cycles thinking about this).  "minimum...of 18 digits" can very readily 
be interpreted to mean "use 64 bits if your hardware encourages that, use 
96 is your hardware prefers that, use 128 if your hardware likes that".  I 
do not believe that the intent was "you must use a decimal notation 
internally and you really ought to implement millions of digits of 
precision".  On the other hand, any implementation that chooses that latter 
interpretation would *also* be conforming.

Hope this helps,
    Jim

========================================================================
Jim Melton --- Editor of ISO/IEC 9075-* (SQL)     Phone: +1.801.942.0144
Oracle Corporation        Oracle Email: jim dot melton at oracle dot com
1930 Viscounti Drive      Standards email: jim dot melton at acm dot org
Sandy, UT 84093-1063              Personal email: jim at melton dot name
USA                                                Fax : +1.801.942.3345
========================================================================
=  Facts are facts.  However, any opinions expressed are the opinions  =
=  only of myself and may or may not reflect the opinions of anybody   =
=  else with whom I may or may not have discussed the issues at hand.  =
======================================================================== 



