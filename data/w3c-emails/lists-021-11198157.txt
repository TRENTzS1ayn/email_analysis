docno="lists-021-11198157"
received="Thu Apr  8 14:18:34 2004"
isoreceived="20040408181834"
sent="Thu, 08 Apr 2004 14:22:10 -0400"
isosent="20040408182210"
name="Thomas B. Passin"
email="tpassin@comcast.net"
subject="Re: How does RDF/OWL formalism relate to meanings?"
id="40759852.4040300@comcast.net"
charset="us-ascii"
inreplyto="p06001f35bc9b305402cc&#64;[10.0.100.76]"
expires="-1"


To:public-sw-meaning@w3c.org


To add a bit to what Pat just posted -

Pat Hayes wrote:
> 
> At this  point a miracle occurs.  Machines CANNOT "get" human-level 
> meanings of words. Sorry, but its just a fact. Ive been working in AI 
> now for over 30 years, and I wish sincerely that they could, but I know 
> they can't, and aren't likely to be able to in the forseeable future 
> (IMO: others are more optimistic.)  However, on the bright side, they 
> can 'get' some of it, for some purposes, and do useful things with the 
> little glimmerings of it that they can get; and by virtue of being able 
> to run with this little amount of knowledge at remarkable speeds over 
> remarkable amounts of data, can do things with it that humans couldn't 
> possibly do.
> 

In terms of John Black's questions, I think it would be **very** 
unlikely if he were to ask the machines handling the information to do 
the same things with it that he expects a person to do.  The trick is 
not to cause the machines to "understand" the same "meanings" as the 
humans.  Instead, the trick is to enable them to do just the amount of 
processing and handling they need to do whatever job is expected of 
them.  That is almost always far less demanding than a full human 
"understanding" would call for.  Or, at least, we have to arrange things 
that way for our dumb computers.

Cheers,

Tom P



