docno="lists-022-14587064"
received="Tue Feb  4 11:07:39 2003"
isoreceived="20030204160739"
sent="Tue, 04 Feb 2003 10:31:34 -0500"
isosent="20030204153134"
name="Al Gilman"
email="asgilman@iamdigex.net"
subject="Re: TT and subtitling"
id="5.1.0.14.2.20030204100756.024e89e0@pop.iamdigex.net"
charset="us-ascii"
inreplyto="-1167774180geoff_freed&#64;wgbh.org"
expires="-1"


To:<public-tt@w3.org>


At 08:45 AM 2003-02-04, geoff freed wrote:


> >Captioning is NOT always in the language of the program audio - for example
> >in the UK it is perfectly feasible on DTT (digital terrestrial TV) to have
> >English subtitles AND English captions (as separate user selections) for a
> >Welsh language (audio) program. To adopt the above definition would mean
> >that any 'foreign language' program that is **not** dubbed could only be
> >termed 'subtitled' - regardless of the inclusion of audio events and
> >narration (which are indicative of captioning cf subtitling).
>
>Talk about head-spinning...
>
>It is becoming apparent that we should consider a broader definition of 
>subtitle vs
>  caption.  That is, not differentiating subtitles from captions based on 
> language, but
>  based on content:
>
>-- captions contain additional information (sound effect cues, identifiers)
>-- subtitles contain no additional information
>
>In other words, the language of the original soundtrack *could*
>become irrelevant.
>
>Arguments?

Well, we do know that we will have independent variation in natural language
and on the above axis.  But we have markup structures and terms for natural
language.

I don't believe that we have got to the bottom of this, yet, though.

You do have your hands on a key aspect of differentiation.

But even this has two factors.

One is coverage:  does the text track cover what is said in the sound track,
or does it cover more by way of sounds or action.  [And terms/language to 
describe
the answer to "if more, then what?"]

But aside from texture, there is the granularity of comparison in
determining the goodness of fit.  Some captions will abridge the dialog.
The same information in different words.  That is to say, they will describe
what is said in the sound track in other words, even 'though in the same
natural language.  These are useful in educational and learning-difficulty
applications.

So the dimensions of the problem at least subdivide into

- relationship between the natural languages of the two tracks
.. this can be based on comparing values of a unary 'naturalLanguage' 
property of the tracks
- relationship between the coverage of one track relative to the kinds of 
sounds in the
   other track.
- other distinctions such as the reading level of the diction used in the 
variant
   as distinguished from the related variant track.

Candidate primitive terms in a Dublin Core sense in this application are

- natural language (done)
- language level [TBD -- education community in the lead -- ISO/IEC JTC1 
SC36 LCFA]
- kinds of sounds (speech, [other categories to be named -- 
effects?  sonicons?  wallpaper? action? -- Dublin Core -like process of 
intercommunity harmonization of concepts]
- rough order of coverage [fragmentary, substantial, partial]

And all of these things are qualified by scoping them to media objects we 
can point at.

Captions and subtitles are both supplemental resources that find their 
principal use
in conjunction with other tracks.

Al

for more on the variety of use cases:

http://trace.wisc.edu/world/modtrans/

No, we can't command changes to usage canonized in existing accredited 
standards.

But the precision of the language used in their definitions is inadequate 
to capture
distinctions that are important in assitive applications and adaptation 
choices.

So we need to create a mapping [with noted ambiguities] between their 
definitions
and the axes of distinction that matter in our applications.  Then they 
might join
us in DCMI to define a migration path to more universal language.


>Geoff/NCAM
>
>
>On Tuesday, February 4, 2003, Johnb@screen.subtitling.com wrote:
> >
> >Geoff Freed wrote:
> >
> >       > SMPTE's definitions leave room for ambiguity.  Captions are always
> >in the
> >       > same language as the program audio, for example, and they aren't
> >limited to just
> >       > motion  pictures.  I propose the following definition for
> >captions:
> >
> >       > "Textual representation of dialog, narration and other audio
> >events, in the same
> >       > language as the original presentation."
> >
> >Captioning is NOT always in the language of the program audio - for example
> >in the UK it is perfectly feasible on DTT (digital terrestrial TV) to have
> >English subtitles AND English captions (as separate user selections) for a
> >Welsh language (audio) program. To adopt the above definition would mean
> >that any 'foreign language' program that is **not** dubbed could only be
> >termed 'subtitled' - regardless of the inclusion of audio events and
> >narration (which are indicative of captioning cf subtitling).
> >
> >I agree that the scope of the definition could be widened in the TT standard
> >to include all video and audio material (not just motion
> >pictures).
> >
> >regards
> >
> >John Birch.
> >
> >The views and opinions expressed are the author's own and do not necessarily
> >reflect the views and opinions of the Screen Subtitling Systems
> >Limited.
> >



