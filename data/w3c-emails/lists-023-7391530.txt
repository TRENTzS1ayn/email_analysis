docno="lists-023-7391530"
received="Tue Feb 25 19:36:07 2003"
isoreceived="20030226003607"
sent="Tue, 25 Feb 2003 13:16:01 -0500"
isosent="20030225181601"
name="Al Gilman"
email="asgilman@iamdigex.net"
subject="Re: RDIG Call for Presenters (recording &ndash;&ndash;&gt; real&ndash;time   transcript)"
id="5.1.0.14.2.20030225130423.02f7f190@pop.iamdigex.net"
charset="us-ascii"
inreplyto="RDIG Call for Presenters (recording &ndash;&ndash;&gt; real&ndash;time   transcript)"
expires="-1"


To:"Markku T. Hakkinen"<hakkinen@dinf.ne.jp>
Cc:public-wai-rd@w3.org


In my stream-of-unconsciousness remarks I mentioned iDictate.  That is a
non-real-time
commercial speech-to-text path.

I recommend that the even use something like that rather than relying
entirely on someone trying to capture a summary in real time.  Real-time
summarization should be part of the
conversation: echoing with participant opportunity to confirm/deny right there.

Some related footnotes.

If we get a person with a hearing loss as one of the participants, we need
to upgrade the infrastructure of the real-time event somehow.  If they are a
sign language user, they may just be supported by interpreters at their site.

If they are happy to work with a text transcript, something like the service
offered by Caption First or Viable Technologies can be slipped in as an
upgrade (real-time plus later corrected)..

Al



