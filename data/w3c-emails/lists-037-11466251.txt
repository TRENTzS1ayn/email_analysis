docno="lists-037-11466251"
received="Thu Feb 27 14:43:53 1997"
isoreceived="19970227194353"
sent="Thu, 27 Feb 1997 11:39:36 -0800 (PST)"
isosent="19970227193936"
name="Gregory J. Woodhouse"
email="gjw@wnetc.com"
subject="Re: Email access to DAV functionality"
id="Pine.SGI.3.95.970227111521.3371A-100000@shellx.best.com"
charset="US-ASCII"
inreplyto="9702271038.ZM4313&#64;twaxx.twaxx.com"
expires="-1"

To: -=jack=-<jack@twaxx.twaxx.com>
cc: Dan Connolly<connolly@w3.org>, Jim Whitehead<ejw@ics.uci.edu>,w3c-dist-auth@w3.org


On Thu, 27 Feb 1997, -=jack=- wrote:

> 
> I've been lurking also, and will now register my two cents on this.
> I do believe that some manner of disconnected operation is desirable,
> but I've never really seen an email interface to such functionality
> that wasn't a blight upon the world of software in general.  To get
> more to the point, disconnected operation is good, (although I'll
> agree it may take significant effort to get that functionality right),
> but doing it via email is definitely bad.  Anyway, that's my feeling,
> 
> -=jack=-
> 
> (This text composed by voice)
> 

I've also been very quiet since the Xerox PARC meeting and have been
reluctant to jump into the fray (so to speak). Basically, I also believe
disconnected operation is a necessity, though I believe that it was
declared out of scope because of difficulty of the issues involved, and the
necessity of meeting specific deadlines. If disconnected operation is out
of scope now, I'd like to see it listed as "future work".

That being said, I see no theoretical reason why WEBDAV couldn't operate
over SMTP (because HTTP is, after all, a request/reply protocol), but agree
that most WEBDAV operations are sufficiently complex (involving multiple
requests) that practical operation over e-mail with existing protocols
seems unlikely. For example, what would be the implications of checking out
(and locking) a document for hours, or even days at at time? It seems to me
that the main problem here is finding a suitable way to synchronize
multiple copies of a webspace when there is no global clock. I also suspect
that a high latency environment like this would only be feasible with
finely grained locking, and I still hve my doubts about rangle locking (and
don't we really want to lock media specific units like HTML elements?)
Perhaps if all HTTP proxies involved are able to cache byte ranges AND
provide suitable validators in such a way tat an entity is valid whenever
it is the union of valid byter ranges, then I think it could work. But I
don't see how this is possible.

---
gjw@wnetc.com    /    http://www.wnetc.com/home.html
If you're going to reinvent the wheel, at least try to come
up with a better one.



