docno="lists-037-4438943"
received="Tue Oct 29 20:57:10 1996"
isoreceived="19961030015710"
sent="Tue, 29 Oct 1996 16:18:38 PST"
isosent="19961030001838"
name="Larry Masinter"
email="masinter@parc.xerox.com"
subject="Re: POST vs. separate methods"
id="96Oct29.161838pst."2763"@golden.parc.xerox.com"
inreplyto="9610292040.aa17741&#64;gonzo.ben.algroup.co.uk"
expires="-1"

To:ben@algroup.co.uk
CC:gjw@wnetc.com,ejw@kleber.ics.uci.edu,w3c-dist-auth@w3.org


> I like this idea - but it isn't very practical, I fear. If the request is
> handled by a CGI, then how does the server know what's been updated? For highly
> automated sites, the list of URLs could be huge.

a) use patterns to invalidate (mark stale) many URLs at once
   (this was the '*' in http://host.dom/container/3q96/*)

b) Don't invalidate if you don't care about sequential transparency
c) If you don't want to invalidate things because there are too many
   and you don't want to warn about updates, then don't let servers
   cache them without validation (e.g., send them out originally with
   max-age=0).

So, I disagree that it 'isn't very practical': it's practical in many
situations, and when it's not practical, you don't have to use it.

Larry



