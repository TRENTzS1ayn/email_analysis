docno="lists-044-16010715"
received="Thu Aug 31 15:34:01 2000"
isoreceived="20000831193401"
sent="Thu, 31 Aug 2000 15:33:56 -0400"
isosent="20000831193356"
name="Joseph M. Reagle Jr."
email="reagle@w3.org"
subject="Re: Mixed Content Model for Transform?"
id="4.3.2.7.2.20000831152812.02c64b58@rpcp.mit.edu"
charset="us-ascii"
inreplyto="NDBBIMACDKCOPBLEJCCDKEEHCKAA.gregor.karlinger&#64;iaik.at"
expires="-1"


To:"Gregor Karlinger"<gregor.karlinger@iaik.at>
Cc:"XMLSigWG"<w3c-ietf-xmldsig@w3.org>

At 13:36 8/31/2000 +0200, Gregor Karlinger wrote:
>Why is the content model chosen for the Transform element "mixed"?

The theory was that people might want to provide elements or charactered 
data (or both) since we could not anticipate the various expressions and 
transforms applications might want to perform.

>All other elements which describe an Algorithm, like
>
>* SignatureMethod
>* DigestMethod
>* CanonicalizationMethod

But that these were rather straightforward.

>is "elementOnly". My way of thinking is that if I would like to
>specify parameters for an algorithm, I have do invent an Elemenent
>which I can then put into the Transform Element representing the
>algorithm.
>
>Why is it allowed to specify text as parameter content for a
>Transform, whereas it is forbidden for all other types of algorithms?

There's no compelling argument that this must be the way it is. Are you 
suggestion we move all the Methods to mixed as well?


_________________________________________________________
Joseph Reagle Jr.
W3C Policy Analyst                mailto:reagle@w3.org
IETF/W3C XML-Signature Co-Chair   http://www.w3.org/People/Reagle/



