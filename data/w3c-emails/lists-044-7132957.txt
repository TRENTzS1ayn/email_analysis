docno="lists-044-7132957"
received="Fri Jun 23 18:04:03 2000"
isoreceived="20000623220403"
sent="Fri, 23 Jun 2000 15:03:49 -0700"
isosent="20000623220349"
name="John Boyer"
email="jboyer@PureEdge.com"
subject="RE: No Character Normalization?"
id="BFEDKCINEPLBDLODCODKIEHECDAA.jboyer@PureEdge.com"
charset="us-ascii"
inreplyto="Pine.SOL.4.21.0006231439310.10341-100000&#64;bugs.valicert.com"
expires="-1"

To:"Kevin Regan"<kevinr@valicert.com>,<w3c-ietf-xmldsig@w3.org>


Hi Kevin,

I appreciated your email, however, I did not get it (due to a meeting) until
after it was already answered.  Full credit for the informative and
authoritative answer belongs to John Cowan.

Sincerely,
***************************************
John Boyer,
Software Development Manager

PureEdge Solutions (formerly UWI.Com)
Creating Binding E-Commerce

v:250-479-8334, ext. 143 f:250-479-3772
1-888-517-2675  http://www.PureEdge.com
***************************************



-----Original Message-----
From: Kevin Regan [mailto:kevinr@valicert.com]
Sent: Friday, June 23, 2000 2:58 PM
To: jboyer@PureEdge.com; w3c-ietf-xmldsig@w3.org
Subject: RE: No Character Normalization?



John,

Thanks for the information.

My greatest concern is to not have to tell my customer that "No, I
can't sign that.  How did you create that document anyway?"

If it is the usual case that documents are created in the normalized
form, then it does not seem like a big issue.  What would happen
in the case of an editor or application written in Java (Unicode)?
It seems that this is the most important case given the close
coupling of Java and XML.

Another concern is whether a document can become "de-normalized" during
transmission.  My previous question was not specific enough. I understand
that documents can be converted to other character formats. However, I'm
wondering if a document can leave one application in a normalized form, go
through various character encodings, and enter another application
with the characters no longer normalized (e.g.  A Java application to Java
application might go from Unicode, to UTF-8 for transmission, and then
back to Unicode in the other application).

Finally, you mention that the detection of a non-normalized document
would aid in the discovery of forgery.  My question is: should similar
documents with different character models be equivalent?
What would most people expect?  I don't really understand the usage
enough to have an opinion on this...

--Kevin



