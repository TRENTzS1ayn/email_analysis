docno="lists-044-8347605"
received="Mon Jan 24 18:03:25 2000"
isoreceived="20000124230325"
sent="Mon, 24 Jan 2000 18:03:12 -0500"
isosent="20000124230312"
name="Joseph M. Reagle Jr."
email="reagle@w3.org"
subject="Re: W3C XML Canonicalization &ndash;&ndash; must read"
id="3.0.5.32.20000124180312.0093f540@localhost"
charset="us-ascii"
inreplyto="01E1D01C12D7D211AFC70090273D20B101C4A9E1&#64;sothmxs06.entrust .com"
expires="-1"


To: Ed Simon<ed.simon@entrust.com>
Cc:w3c-ietf-xmldsig@w3.org

At 23:28 00/01/21 -0500, Ed Simon wrote:
 >Two areas we know we need to explore are the octet representation
 >of characters (eg. the character model)

To that end, the snippets of the relative reports are below:

http://lists.w3.org/Archives/Public/www-xml-canonicalization-comments/2000Jan/0000.html

Relative to the rest of XML C14N, I believe Unicode C14N is relatively
complex and resource intensive.  It will make a significant difference
to either code size or speed (you can probably implement slowly in a
little code, or fast in a lot of code).  In the context of its use for
digital signatures, XML C14N needs to be performed in scenarios where
processing resources are strictly limited. 

http://lists.w3.org/Archives/Public/www-xml-canonicalization-comments/2000Jan/0001.html

The overhead of normalization is not large in code space or data space or
time.  I have provided a non-normative explanation of the algorithm at ...
In general, a table space of about 8K bytes is involved, and the process
is O(N) except on pathological data.


_________________________________________________________
Joseph Reagle Jr.   
Policy Analyst           mailto:reagle@w3.org
XML-Signature Co-Chair   http://www.w3.org/People/Reagle/



