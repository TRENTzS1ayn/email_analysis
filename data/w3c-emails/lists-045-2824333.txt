docno="lists-045-2824333"
received="Wed Nov 29 19:45:12 2000"
isoreceived="20001130004512"
sent="Wed, 29 Nov 2000 16:45:01 -0800"
isosent="20001130004501"
name="Paul Hoffman / IMC"
email="phoffman@imc.org"
subject="RE: Character Encoding Question"
id="p050104a1b64b51747acc@[165.227.249.17]"
charset="us-ascii"
inreplyto="BFEDKCINEPLBDLODCODKIELGCGAA.jboyer&#64;PureEdge.com"
expires="-1"


To:"John Boyer"<jboyer@PureEdge.com>,<w3c-ietf-xmldsig@w3.org>

At 3:58 PM -0800 11/29/00, John Boyer wrote:
>Anyway, Jeff's point about UCS-2 != Unicode has now hit home thanks to some
>of the examples in the UTF-8 spec.  These examples clearly show triplets of
>UCS-2 values being used to form a single character, which does not appear to
>be permissible under UTF-16.

It appears that you are badly mis-reading the UTF-8 spec. None of the 
examples show "triplets of UCS-2 values being used to form a single 
character".

>   Since the Unicode manual is quite clear on the
>equivalence between Unicode and UTF-16 (p. 19), this would mean that UCS-2
>!= Unicode.

There isn't anything on p. 19 that says what you say. What p. 19 says 
is "The default encoding form of the Unicode Standard is 16-bit". A 
default encoding is far from saying that there is an equivalence.

>So it would seem that we need to include UCS-2 in the list of things that
>should not have NFC applied.

<sigh> I think I'm just going to let Martin sort this out; that's his job.

--Paul Hoffman, Director
--Internet Mail Consortium



