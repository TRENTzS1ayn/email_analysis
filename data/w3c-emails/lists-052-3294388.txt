docno="lists-052-3294388"
received="Mon Aug  4 12:28:24 2003"
isoreceived="20030804162824"
sent="Mon, 04 Aug 2003 12:28:08 -0400"
isosent="20030804162808"
name="Martin Duerst"
email="duerst@w3.org"
subject="RE: XML literals"
id="4.2.0.58.J.20030804121542.05026b48@localhost"
charset="us-ascii"
inreplyto="XML literals"
expires="-1"


To:Patrick.Stickler@nokia.com
Cc:w3c-rdfcore-wg@w3.org


At Mon, 4 Aug 2003 10:53:45 +0300, Patrick.Stickler@nokia.com wrote:

 > Fine, then we define it ourselves. Let the lexical form itself be the 
UTF8 encoded canonical form

No other lexical form is UTF-8 encoded. Lexical space is always
on strings of characters, irrelevant of encoding.

 > (full Unicode support is provided by RDF/XML serialization and/or 
various editorial interfaces)
 > and XML literals are self denoting, just like plain literals.

Would that mean that they are still equal to hexBinary?

 > No need to map from Unicode to UTF8.
 > No need to posit a value space based on some other specification. They 
are exactly what they
 > are in the graph, and string equality provides for value comparison.

String equality? Or octet sequence equality?

 > And being canonicalized XML fragments, implementors know what the values 
are and what to
 > do with them.

Overall, I'm wondering why you are opposed to have them 'different
from everything else', but are okay with 'same as octet sequences'
if you claim that implementers anyway know what to do with them,
i.e. treat them as canonicalized XML fragments.

Maybe this is some basic unease at having something undefined.
This would indeed allow others to write an implementation that
would treat them as pumpkins. But who would seriously do that?

Neither equating XML fragments with octet sequences nor equating
them with pumpkins seems very adequate. And it seems strange to
me that we would have to do something rather inadequate just to
avoid something maybe even more inadequate, in particular if
that other thing (the pumpkins) is utter nonsense.


Regards,    Martin.



