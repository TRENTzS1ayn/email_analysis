docno="lists-053-11423227"
received="Fri Oct 31 08:29:35 2003"
isoreceived="20031031132935"
sent="Fri, 31 Oct 2003 15:27:01 +0200"
isosent="20031031132701"
name="Patrick Stickler"
email="patrick.stickler@nokia.com"
subject="Re: non english labels/comments for rdf.rdf and rdfs.rdf"
id="BBC82FC5.40A8%patrick.stickler@nokia.com"
charset="US-ASCII"
inreplyto="zVesn.A.AaG.Ihmo_&#64;metia"
expires="-1"

To: ext Graham Klyne<gk@ninebynine.org>, Brian McBride<bwm@hplb.hpl.hp.com>
Cc: Dan Brickley<danbri@w3.org>,<w3c-rdfcore-wg@w3.org>,<swick@w3.org>



On 2003-10-31 14:49, "ext Graham Klyne" <gk@ninebynine.org> wrote:

> At 12:26 31/10/03 +0000, Brian McBride wrote:
>> My goal here is to ensure that we have an appropriate document at the end
>> of the RDF namespace URI when we go to PR.
>> 
>> Graham Klyne wrote:
> 
> (Actually, Patrick wrote this...  I just agreed)
> 
>>>> Would it not make more sense to have distinct schemas for
>>>> each languages labels. I.e.
>>>> 
>>>> rdf_fr.rdf
>>>> rdf_sp.rdf
>>>> rdf_ge.rdf
>>>> rdf_fi.rdf
>>>> etc.
>> 
>> I don't think so.  How would an application find them?
> 
> How would an application find *any* new information that appears after the
> original schema document is published?  How does one draw the line between
> what languages are included and what are not.  These are problems that the
> sweb will have to address in any case, probably in numerous ways.

And one way is to use something like URIQA, where the nitty gritty
management issues such as which "files" must be downloaded to get
information about a given term simply go away.

You'd simply use MGET to obtain a description of e.g. rdfs:seeAlso
and it would include whatever labels in whatever languages were
defined authoritatively by the W3C, and the W3C is then free to
decide how it wants to partition and manage its knowledge.

> Actually, where Patrick wrote "different schemas", I don't think the
> language-neutral schema information should be duplicated -- I read the
> comment as suggesting that the separate files have just the alternative
> language annotations, and could be read in addition to the primary schema
> file.  

Exactly.

The language specific schemas would only *add* to the knowledge
about the vocabulary.

> I would imagine that the various language document would link back
> to the original schema in some way (<> rdfs:augments <SchemaURI>?) so that
> semantic web crawlers would be able to build appropriate indexes.

They could.

Though with an approach such as URIQA, there's no need to link back at all,
since one can obtain the knowledge one needs irrespective of how it is
managed. If one wishes to know about a given term, one just asks. No need
to figure out which and how many large schemas to download, parse, and
process to extract the information needed about a single resource.

Patrick


> if you
> (I don't feel strongly either way about the original suggestion, unless
> this is likely to delay publication while we wait for the appropriate
> language text to be available.)
> 
> #g
> 
> 
> ------------
> Graham Klyne
> For email:
> http://www.ninebynine.org/#Contact
> 
> 



