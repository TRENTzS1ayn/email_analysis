docno="lists-059-15158946"
received="Mon Oct 22 14:57:23 2001"
isoreceived="20011022185723"
sent="Mon, 22 Oct 2001 13:57:01 -0500"
isosent="20011022185701"
name="Phill Jenkins"
email="pjenkins@us.ibm.com"
subject="Re: EARL use scenario / technique"
id="OFB9C3DA97.C5051D99-ON86256AED.00675F17@raleigh.ibm.com "
charset="us-ascii"
inreplyto="EARL use scenario / technique"
expires="-1"

To:w3c-wai-au@w3.org


> What are the specific techniques here?
>
> record the reading level of content at each check. If the level
increases, a
> tool may record a suspicion that the relevant checkpoint is not met. If
the
> author is asked explicitly, it may record that the author claims the
> checkpoint is met. For abetter implementation, only do this after
providing
> some repair attempt.
>
> record author's satisfaction with text equivalents. Don't prompt the
author
> to confirm these again if there is a recorded answer and the content has
not
> changed.
>
> chaals

I think the real technique is annotating or having the tool record that the
author checked something and it should be remembered - using EARL as a
language to record it.  I'd call it "Annotating with EARL".

In the example I would like to suggest examples that are more priority 1
and not controversial [more usability and less technical accessibility]
ones like reading level.  For example, using alt="" - null string for
spacer and redundant images should be recorded as "valid" by the author.
Another example would be tables used for layout and real data tables.  The
layout tables could be recorded as "layout" and not checked anymore for
TH's, captions, or headers=.  The tool could also record that the "layout
table" was "linearized" and verified that it "looked" OK to the author.  In
other words all the P1's that require or could benefit from some human
judgement annotations.

Regards,
Phill Jenkins,  (512) 838-4517
IBM Research Division - Accessibility Center
11501 Burnet Rd,  Austin TX  78758    http://www.ibm.com/able



