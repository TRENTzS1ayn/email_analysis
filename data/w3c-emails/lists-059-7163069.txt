docno="lists-059-7163069"
received="Wed Jul 19 12:54:39 2000"
isoreceived="20000719165439"
sent="Wed, 19 Jul 2000 09:53:57 -0700"
isosent="20000719165357"
name="William Loughborough"
email="love26@gorge.net"
subject="contract?"
id="3975DD25.85036FE3@gorge.net"
charset="us-ascii"
expires="-1"


To: au<w3c-wai-au@w3.org>

A couple of things that may seem unrelated to the issue of contracting
out the construction of an "evaluation form" by someone not in/of WAI,
but a professional in creating such systems:

First, when I read Jan's evaluation of the Yahoo authoring tool, I was
struck by the importance of the personal touch in this whole matter.
Uniformity of output seems trivial when the pertinent "feel" for whether
a tool is useful/conformant can be succinctly communicated by a
reasonably knowledgable/concerned person. Conclusion: looking for a
"copout" might just be a means to delay making these kinds of "movie
review" sorts of postings. If the audience is authoring tool developers
(and I hope this is mainly true) - this kind of stuff, particularly when
collected, will get attention.

Second, there is an all-too-familiar process that starts with a concept
("let's help the blind" or whatever), moves to a Web page ("please
forgive us, this site is under construction but..."), becomes a listserv
with initially enthusiastic subscribers, dies a fairly slow unremarked
death. 

The "contract" will divert/delay us in doing what we are uniquely
qualified (however reluctantly) to do - look at the efforts by tool
makers to include accessibility-enhancement in their products. It need
not be a requirement (in fact, I question if it should be) that there
even be a "tool" for this evaluation other than the mind of the
evaluator. The report will serve many purposes and inasmuch as there can
be many evaluations (including those made by the tool designers!) there
is no dearth of promulgation of information about a tool. It's sort of
like a "freehand RDF" or some such.

Even if we do much less than Jan did with Yahoo! we will start a body of
critiques that can be pointed to, particularly if they don't involve
"seals of approval" or conformance logos. They're just notes on which
developers *might* base version N.n.n. 

We are less likely to write "WeaveWebber sucks" or "there's some merit
in the "save as" function of "WebWrite"" if we comfortably assume that
some "expert" who has never even been on a Working Group is taking care
of presenting us with a usable/objective tool - a sort of pantechnicon
type "accessuator".

Simply the unreliability of most "experts"' ability to evaluate if a
tool is itself accessible should give us pause. And will the people who
design this magic instrument be of this community? It's fundamentally
different from deciding whether "savebux 1.2" has bugs/is usable.
Judging by much of the stuff that hits the market, many (most) of these
consultants would have to themselves be carefully
evaluated/monitored/communicated-with - and that process would
substitute for doing it ourselves, however onerous the task might seem.
After all, it's no worse than was compiling a list of potentially useful
tools or writing techniques. 

It is a process without end. It might even serve as a requirement for
membership. Not doing it would be a waste of much of our time together.

That was more than 2d worth and more than I intended to say. I guess I'm
changing my "vote" about putting a contract out for bids. At root I
think it's a copout of sorts and divisive and even counter-productive.
We need to do this ourselves even if only to provide us with insights
into the next step in our own process.

We might even write a sort of review of our own guidelines!

-- 
Love.
            ACCESSIBILITY IS RIGHT - NOT PRIVILEGE
http://dicomp.pair.com



