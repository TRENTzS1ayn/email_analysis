docno="lists-059-7687074"
received="Thu Aug 31 08:16:53 2000"
isoreceived="20000831121653"
sent="Thu, 31 Aug 2000 08:18:19 -0400"
isosent="20000831121819"
name="Jan Richards"
email="jan.richards@utoronto.ca"
subject="Re: Aug. 29 Minutes"
id="39AE4D0B.6588897F@utoronto.ca"
charset="us-ascii"
inreplyto="Pine.LNX.4.21.0008310205220.25806-100000&#64;tux.w3.org"
expires="-1"


To: Charles McCathieNevile<charles@w3.org>
CC:"w3c-wai-au@w3.org"<w3c-wai-au@w3.org>

> It would be good to lok at the checkpoints and see which of them are sinple
> (i.e. there is one test to satisfy) and which are complex. For example, I
> think that 7.6 "Allow the Author to search within editing views" is simple -
> you just answer the question.
>
> 4.1 (and the other relative priority checkpoints), and 5.1 (ensure everything
> is part of the look and feel) are complex - you need to test mutliple things.
>
> But 1.1 is in between. For example, if you can edit source, you meet 1.1. If
> you can't then you need to test for a number of different things that you can
> do in HTML, or whatevber type of content the tool produces (this might be
> easiest for image editors where there isn't much that can be done).
>
> What I am wondering is how we determine what needs to be tested for a given
> type of tool. Maybe by describing it and seeing if we agree.

I think it would be great if we could start every section with a couple of
shortcut questions that allow the tester to skip big chunks if the right thing is
present. Ex. "Can you edit source directly?"  If yes skip to question X.

Cheers,
Jan



