docno="lists-061-4489007"
received="Wed Jul 14 15:58:51 1999"
isoreceived="19990714195851"
sent="Wed, 14 Jul 1999 15:57:19 -0400"
isosent="19990714195719"
name="Marja-Riitta Koivunen"
email="marja@w3.org"
subject="curricula comment"
id="3.0.5.32.19990714155719.0098c3a0@localhost"
charset="us-ascii"
expires="-1"


To:cpl@starlingweb.com,Geoff_Freed@wgbh.org
Cc:w3c-wai-eo@w3.org

I was looking the slides again and realized that the synchronization point
is missing in:

Example for Checkpoint
1.3 - Until user agents can automatically read aloud the text equivalent of
a visual track, provide an auditory description of the important
information of the visual track of a multimedia presentation. Example
Slide 19 of 108

- It explains that in the future the audio descriptions can be read from
text. And that I do believe, however, in addition the text needs to be
synchronized to the other tracks. And it might be that the author needs to
create some control to delay or pause the original audio and video tracks
to make space for the audio descriptions. So it is probably not as simple
as just writing the text.

Marja



