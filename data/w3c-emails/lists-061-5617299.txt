docno="lists-061-5617299"
received="Thu Jul 29 09:34:11 1999"
isoreceived="19990729133411"
sent="29 Jul 1999 09:37:42 +0000"
isosent="19990729093742"
name="Geoff Freed"
email="Geoff_Freed@wgbh.org"
subject="Comments on SMIL note"
id="n1278881538.2526@wgbh.org"
charset="ISO-8859-1"
expires="-1"


To:"Judy Brewer"<jbrewer@w3.org>,"WAI-EO"<w3c-wai-eo@w3.org>
Cc:"Ian Jacobs"<ij@w3.org>,"Madeleine Rothberg"<Madeleine_Rothberg@wgbh.org>

                           Subject:                         Time:   9:29 AM
                           Comments on SMIL note            Date:   7/29/99

Comments from Geoff Freed (scribe) and Madeleine Rothberg from NCAM/WGBH.  

====

Everywhere:
It would be very helpful to somehow offset elements and attributes (A, ANCHOR, SYSTEM-CAPTIONS, etc.) from the normal text of this document.  Capitals?

Section 2, Equivalent Alternatives introduction:
There's discussion of auditory descriptions here (beginning in paragraph 2), but there's no definition of the term until section 2.2.  It would be useful to move the definition to the introduction.

Section 2.2:
"Two stream equivalent formats..."

insert hyphen:
Two stream-equivalent formats...

2.2.1
"Since users may have difficulty processing multiple tracks at once, auditory descriptions are generally scheduled to play during the intervals of the sound track with no dialog."

change to:
Auditory descriptions are generally timed to play during the natural pauses in dialog.  However, there may be cases where  these natural pauses are not long enough to accommodate a sufficient auditory description.  In such cases, it will be necessary to pause the video in order to provide enough time for an extended auditory description.  At the end of the description, the video should resume play automatically.

(note:  SMIL 1.0 does not provide attributes for this video-pause feature.  however, i've discovered that it is possible to fake video pauses by sequentially playing parallel groups of video and audio.  this work-around is not ideal; if you want to see how it's done, let me know.)

2.2.3
"Since captions include text descriptions of actions, sounds, etc., in addition to dialog, they can be more helpful than subtitles.  Authors who provide captions need not provide subtitles in the same language since the two are so similar."

1.  Captions can and do describe important off-screen information, like sound effects.  But they really don't describe actions, so this word should be deleted.

2.  It's unwise to equate captions with subtitles.  It is generally accepted that captions are for deaf or hard-of-hearing audiences, and subtitles are for hearing audiences.  As such, captions and subtitles are used for two different purposes and therefore *can* provide two totally different types of information.  A primary distinction between the two is that captions usually indicate important sound cues (like sound effects) whereas subtitles do not, since it is assumed that the hearing person watching the subtitles doesn't need to be told that a particular sound is occuring.

In the case of a simple video presentation, like a class lecture or perhaps a documentary, there may be little or no need for the inclusion of sound-effect captions in the caption file.  In this case, the caption and subtitle files may, indeed, be identical.  But in the case of a mystery program or drama, sound effects may be very important to the action.  In this case, the caption and subtitle files may be quite different.  

If you use the same file for both captioning and subtitling, you run the risk of misinforming or perhaps over-informing one audience.  A deaf viewer relying on subtitles for captions will undoubtedly miss out on some important information.  On the other hand, a hearing person relying on captions for subtitles may become annoyed over the superfluous presence of sound-effect captions.

This is a really philosophical problem more than a technical one.  I would prefer that we not recommend that multimedia authors feel free to use the same text file for both captions and subtitles, but I could be persuaded that, rather than recommending that authors always provide two separate caption and subtitle files, a single *caption* file should be created and used for both purposes.  I would rather risk annoying the hearing audience than shutting out the deaf audience.

Also in 2.2.3:
"The second stream will be rendered if the user has configured the player to prefer subtitles and Spanish."

Add the word "audio" after "Spanish".

Section 4.1:
It looks like you're recommending that authors use SYSTEM-CAPTONS to turn on text links corresponding to a video map.  Aren't you just supposed to use this element for captions only?

Section 6:
Paragraph two, line three:  WAI-WEBCONTENT (technical document) should be WAI-WEBCONTENT-TECHS.

Section 7:
This should be an ordered list, no?

"synchronization elements: 'SYSTEM-CAPTIONS', and 'SYSTEM-OVERDUB-OR-CAPTIONS' attributes (4.4)" is repeated twice.

"Layout element and style languages  (3.2 and 3.3)" needs a colon after "languages".

References:
Delete leading space under CSS-ACCESS

Add quotes to link under SMIL 1.0

That's it.
Geoff Freed
Madeleine Rothberg
NCAM/WGBH



