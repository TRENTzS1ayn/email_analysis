docno="lists-063-10475582"
received="Fri Apr 28 13:06:29 2000"
isoreceived="20000428170629"
sent="Fri, 28 Apr 2000 13:09:26 -0400"
isosent="20000428170926"
name="Wendy A Chisholm"
email="wendy@w3.org"
subject="X3D Conformance Testing"
id="4.2.0.58.20000428125252.00aac940@localhost"
charset="us-ascii"
expires="-1"


To:w3c-wai-er-ig@w3.org

Hello,

In working on an action item for EO I've found some interesting information 
about X3D conformance testing.  It's inspired some random thoughts....

The Web3D consortium, the group of people working on 3D graphics on the Web 
(the evolution of VRML) has been testing both content and user agents for 
conformance.

more info at 
http://www.web3d.org/TaskGroups/x3d/slides/KassConformanceX3dMarch1999/index 
.htm  (note that these are powerpoint slides that have been saved as images 
- grrrr)

I haven't come across details yet, but the are doing some ECMA/JavaScript 
testing.

NIST has a tool called Viper...NIST is also the group of people that 
created WebMetrics.

Before VRML evolved into X3D, there were conformance testing tools.  Some 
of which had over 4000 automated tests.

The current test suite is available from 
http://xsun.sdct.itl.nist.gov/~mkass/x3d/html (NIST)

interesting piece from the documentation:
<blockquote>
The fact that a VRML scene may be static, dynamic, 3-dimensional and/or 
contain sound, necessitates human visual interpretation. Consider a "dotted 
line", a "green" box, a "barking" sound, all common-sense vocabulary of 
human visual and audio perception. Barring exotic technology or extreme 
measures, we must rely on human operators and their ability to "recognize" 
these terms. To minimize the subjectivity inherent in testing browsers, 
careful consideration must be given to the test file design and criteria 
for evaluating the tests.
  ...

By reviewing the testable areas that were apparent from the VRML 
specification, we developed a model that provided some guidance in the 
construction of test cases, rather than approaching these categories in an 
ad hoc fashion. Three major design considerations arose from our review of 
testing methodologies:
Design metafile testing using concepts derived from syntax testing, which 
is realized through the development of a reference parser. The parser 
should be extended to include useful graphical user interface concepts.
Design browser conformance tests using concepts derived from logical 
inferencing. These concepts can be used as guiding principles for the 
creation of semantic requirements and actual test case generation.
Design an interactive testing capability to address the problems associated 
in testing graphics standards. The interface should make use of concepts 
from other computer science disciplines, including database, WWW, and 
human-computer interface technologies.
</blockquote>

It is interesting to consider.  Personally, I never thought about testing 
browser implementations. I do not think that we should, yet in a way to 
satisfy the "until user agents" clauses of WCAG 1.0, we almost need to 
incorporate some knowledge of browser renderings into our tests.

This is obviously nothing new. Bobby already allows this by letting the 
user select versions of various browsers.  Also, we have "lynx-me" type 
services that allow authors to see how pages may be rendered in lynx.

just some thoughts,
--wendy
--
wendy a chisholm
world wide web consortium
web accessibility initiative
madison, wi usa
tel: +1 608 663 6346
/--



