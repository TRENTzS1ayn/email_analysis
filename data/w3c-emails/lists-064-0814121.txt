docno="lists-064-0814121"
received="Wed Mar  1 11:49:24 2000"
isoreceived="20000301164924"
sent="Wed, 01 Mar 2000 10:29:43 -0500"
isosent="20000301152943"
name="Marja-Riitta Koivunen"
email="marja@w3.org"
subject="Re: Determining if a SMIL presenation has captions and an   auditory    description."
id="3.0.5.32.20000301102943.00ee5880@localhost"
charset="us-ascii"
inreplyto="Pine.LNX.4.20.0002232238320.25610-100000&#64;tux.w3.org"
expires="-1"


To: Charles McCathieNevile<charles@w3.org>, Wendy A Chisholm<wendy@w3.org>
Cc:w3c-wai-er-ig@w3.org

At 10:45 PM 2/23/00 -0500, Charles McCathieNevile wrote:
>Also, because text is much more lightweight than video, any text that is
>intended to form part of the presentation may be shipped as such. In that
>case it will most likely not have a system-captions set.
>
>Charles McCN
>
>On Wed, 23 Feb 2000, Wendy A Chisholm wrote:
>
>  I took an action item on the 14 February call to find out how to determine 
>  tracks in SMIL.  It's very straightforward.  Consider the following
example 
>  from the SMIL access note [1]:
>  <par>
>      <audio alt="Interview with Harvey, English audio"
>             src="audio.rm"/>
>      <video alt="Interview with Harvey" src="video.rm"/>
>      <textstream alt="English captions for interview with Harvey"
>                  src="closed-caps.rt"/>
>  </par>
>  
>  This will play an audio track, a video track and a text track (captions).
>  
>  Therefore, it is fairly simple to determine if a text track is associated 
>  with the audio/video tracks.  However, this text track *could* be language 
>  subtitles.
>  
>  Consider the following example:
>  <par>
>      <audio alt="My Favorite Movie, English audio" src="audio.rm"/>
>      <video alt="My Favorite Movie" src="video.rm"/>
>      <textstream alt="Stock ticker" src="stockticker.rt"/>
>      <textstream alt="English captions for My Favorite Movie"
>                  system-captions="on"
>                  src="closed-caps.rt"/>
>  </par>
>  
>  It uses the "system-captions" attribute to indicate to a SMIL player that 
>  if the user wants captions this is the track to play.  I don't know if we 
>  want to get into repairing SMIL, but if we find a SMIL presentation
without 
>  the "system-captions" flag we could raise a warning.
> 

And even if the system-captions flag is found it may be used for other
purposes than a caption element or it may just attach captions for a part
of the audio elements.

Marja

>  SMIL 1.0 does not have a similar flag for auditory descriptions, although 
>  it is being discussed for the next release.  Multiple audio tracks can be 
>  included, but they could be used for language overdubbing.
>  
>  Therefore, checking for captions is currently more straightforward than 
>  checking for an auditory description, but there are clues that you can use 
>  to make a guess and ask the author for confirmation.
>  
>  --wendy
>  
>  [1] http://www.w3.org/TR/SMIL-access/
>  --
>  wendy a chisholm
>  world wide web consortium
>  web accessibility initiative
>  madison, wi usa
>  tel: +1 608 663 6346
>  /--
>  
>
>--
>Charles McCathieNevile    mailto:charles@w3.org    phone: +61 (0) 409 134 136
>W3C Web Accessibility Initiative                      http://www.w3.org/WAI
>Location: I-cubed, 110 Victoria Street, Carlton VIC 3053
>Postal: GPO Box 2476V, Melbourne 3001,  Australia 
>



