docno="lists-064-13050872"
received="Mon Nov 26 02:41:17 2001"
isoreceived="20011126074117"
sent="Mon, 26 Nov 2001 02:41:14 -0500 (EST)"
isosent="20011126074114"
name="Charles McCathieNevile"
email="charles@w3.org"
subject="Re: My first EARL client.."
id="Pine.LNX.4.30.0111260236180.16463-100000@tux.w3.org"
charset="US-ASCII"
inreplyto="013f01c16c9b$c84ffae0$3c3c70c2&#64;7020CT"
expires="-1"

To: Jim Ley<jim@jibbering.com>
cc:"Sean B. Palmer"<sean@mysterylights.com>,<w3c-wai-er-ig@w3.org>


On Tue, 13 Nov 2001, Jim Ley wrote:

  Indeed, but I don't find date and version sufficient for my needs, the
  problem being with those sites who do server side negotiation of some
  sort, it's no use me doing an EARL report only to find it's actually
  totally different if I sent an SVG accept header (or even HTTP_USER_AGENT
  <spit>.) or for sites who don't send last modified (despite the content
  being identical each time.)  I'm imagining whenever content is found to be
  different it's scheduled for a revisit by a robot to do new tests (or
  automatically done by the client itself, depending on how the checks do
  pan out.).
CMN
One of the things we don't have in EARL (as far as I know - I have not
followed it for a few weeks) is a way to provide more comprehensive context
information - encode the HTTP request sent for example, or CC/PP if you
happen to be using it.
Jim:
  I have one question, that you're probably best served to answer - How do I
  combine two EARL reports, say a validation pass, but then a human coming
  in and saying, No, that's no good it fails WCAG 3.1 - how would I combine
  those in a single EARL report? - at the moment I was just going to use my
  moomin report as a catchall for a whole basket, but I might aswell do it
  properly and actually collate the reports of different test tools into
  one.
CMN
Well, the question of how to merge 2 chunks of RDF is mostly one for the RDF
group, who work on such things, but there is a bit we should deal with - how
to decide whether one report invalidates another, or whether a particular
user should be asked to configure their trust rankings, or whether two
reports are in fact compatible if contradictory and the information should be
there from both of them.

For example, a tool says "there is no alt attribute" and then 10 minutes
later says "there is an alt attribute". Should the tool try to delete its
earlier statement (this is possible with Annotea annotations) and replace it,
or should it note that there is a thread, and provide a set of rules for
merging data?

cheers

Chaals



