docno="lists-065-0180281"
received="Mon Jun 17 14:33:46 2002"
isoreceived="20020617183346"
sent="Mon, 17 Jun 2002 14:32:45 -0400 (EDT)"
isosent="20020617183245"
name="Charles McCathieNevile"
email="charles@w3.org"
subject="Re: Devising a schema for accessibility testing"
id="Pine.LNX.4.30.0206171427050.23534-100000@tux.w3.org"
charset="US-ASCII"
inreplyto="20020617112015.P439-100000&#64;fenris.webthing.com"
expires="-1"

To: Nick Kew<nick@webthing.com>
cc:<w3c-wai-er-ig@w3.org>



We have been thinking along similar lines. HiSoftware's interview toy deals
with things that require manual checking (as I understand the press info) and
defines an XML vocabulary for adding your own questions and appropriate
responses.

Nadia's MUTAT worked from RDF information. Dan Brickley worked on something
similar (or worked with people who did) for more general school exam type
stuff.

In the early stages of EARL development we talked about whether it should
encompass test questions as well. We decided not to do that - as I recall
because we didn't know enough about what kind of questions we would be asking
at the time. I don't think that is a bad decision - the fact that we settled
on RDF means that we can relatively easily integrate a new vocabulary of
questions (or even several different ones ;-).

It seems to me that there would be some value in having an RDF version of the
information available - this would enable you to compare tests you have to
tests in other tools, and say "I don't need to ask tis question if there is
an existing result for a question in MUTAT that covers it" (or maybe you
do...  let the user decide if they want to change the defaults).

Of course there is no reason why you can't start from an XML schema and
transform the information to RDF, or even have an XML schema that matches RDF
syntax requirements...

(No time to answer this properly here, but I thought I would add my thoughts
since I had originally planned to write about this today).

cheers

Chaals

On Mon, 17 Jun 2002, Nick Kew wrote:

  As you know, Page Valet incorporates a set of tests to evaluate documents
  against a set of guidelines such as WCAG or US Section 508.

  Further development using mod_xml now puts me in a position to generalise
  this.  Instead of having hardwired tests, Valet should be able to read a
  spec from a schema, and so apply a user's own testsuite.  The key change
  that makes this feasible is that mod_xml can precompile and cache a
  schema, rather than having to parse from scratch every time an
  evaluation is run (or hardwire it, as in the present Page Valet).

  Now I'd like to seek your views on how to go about this.  Is an RDF schema
  a good option here, and what should it look like?  Or would I be just as
  well-off with a semantic-free XML schema?



