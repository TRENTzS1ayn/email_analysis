docno="lists-066-16140672"
received="Thu Dec 16 09:55:49 1999"
isoreceived="19991216145549"
sent="Wed, 15 Dec 1999 14:40:01 -0500"
isosent="19991215194001"
name="Bruce Bailey"
email="bbailey@clark.net"
subject="RE: Captions for audio clips"
id="01BF479A.A94573A0.bbailey@clark.net"
charset="us-ascii"
inreplyto="Captions for audio clips"
expires="-1"


To:"w3c-wai-gl@w3.org"<w3c-wai-gl@w3.org>
Cc:"'Charles McCathieNevile'"<charles@w3.org>,"'pjenkins@us.ibm.com'"<pjenkins@us.ibm.com>

Dear Phill (et al.)

IMHO, it is a clear case of P2!

Populations effected:  Persons for whom English is a second language. 
 Persons who are not deaf but have impaired hearing.  Persons with learning 
disabilities for whom processing auditory information is difficult (but not 
impossible).

The assumption is that ALL of the above persons might very well PREFER an 
audio stream for the SAME REASONS everyone else prefers audio over a text 
transcript.  Is it a useful exercise for use to delineate why an aural 
presentation is better (in some cases) than a textual one?

From this perspective, the situation is very analogous to persons with VERY 
poor vision who STILL PREFER a GUI browser!  We are empathetic / 
sympathetic to this orientation.  Just as we accommodate the partially 
sighted, so should we adjust for the hard of hearing.

For the above populations, "unimedia audio" represents a significant 
barrier to their access of content (we are using RealAudio radio broadcasts 
as an example).

For the above populations, a separate transcript has so little value as to 
be virtually useless -- just as access to Lynx is not well regarded a 
viable option for web surfing by most persons with vision impairments (nor 
most average people for that matter).

It is, of course, important to have techniques on hand, but that should not 
influence the assignment of Priorities.

Does anyone have an example of captioned audio?

I experimented with some SMIL file on my local hard drive.  I could get 
RealAudio (actually a .rm RealMedia file) to play ONLY the sound (with 
synchronized captions), but I could NOT get rid of the blank video window. 
 Probably I am just doing something wrong, but I did look at the W3C SMIL 
specifications.  Does the W3C offer a SMIL validation service?

Bruce Bailey


On Sunday, December 12, 1999 11:52 PM, Charles McCathieNevile 
[SMTP:charles@w3.org] wrote:
> Phill, if you are just reading it then that is the case. However for 
people
> who have marginal hearing, having the sound and the captions/score 
available
> and synchronized is more valuable than one or the other (similarly for 
people
> who can hear, but have difficulty reading). One of the challenges we face 
is
> that there are people who are looking for multi-modal support - there are
> more people with poor hearing than there are with no hearing (and 
similarly
> for other disabilities).

On Wednesday, December 15, 1999 11:45 AM, pjenkins@us.ibm.com 
[SMTP:pjenkins@us.ibm.com] wrote:
> JW:
>> It appears to be broadly agreed within the group that a requirement to
>> synchronize text transcripts with audio presentations should be
>> established, at least at a priority 2 level.
>
> PJ:
> Where is the broad agreement?  Bruce, Jason, and Charles seem to agree 
with
> P2.  I'm arguing for P3, and Robert and Eric seem OK with either P2 or 
P3,
> and I haven't heard form others.  I do agree that there seems agreement
> that we need to make the distinction between multimedia videos and 
unimedia
> sounds files in the errata so that WCAG 1.4 doesn't apply to the unimedia
> sound only files.
[snip]
> PJ:
> but I've heard no supporting rationale or any convincing evidence that
> suggests that the "value" is more than useful and improves accessibility
> [P3].
>
> Because the deaf,  [learning disabled, or those learning a foreign
> language] are so comfortable now with synchronized television (and movie)
> captioning, does not support the argument that they will be comfortable 
or
> have significant barriers removed with synchronized captioned audio only
> files.  Can anyone even show me an sample example, or better yet, a real
> example on the Web or anywhere?  If we don't add a supporting technique, 
a
> checkpoint requiring [even at P3] synchronized captions for audio only
> files shouldn't even be added to the guidelines.  I've seen natural
> language courses use techniques of synchronization to TEACH the language,
> but we're talking about guideline 1 - equivalent alternative information 
-
> not "teaching natural languages" or "teaching singing".  We have been
> talking about ideas and theories, how can we suppose that it fits the
> definition of "significant barriers".  P3 is still "valuable" and 
"useful"
> and "improves accessibility".



