docno="lists-066-2643055"
received="Sun Apr 25 23:27:10 1999"
isoreceived="19990426032710"
sent="Sun, 25 Apr 1999 23:27:07 -0400 (EDT)"
isosent="19990426032707"
name="Alan Cantor"
email="acantor@oise.utoronto.ca"
subject="Guideline 9 &ndash;&ndash; Editorial clarification"
id="Pine.SOL.3.91.990425225932.22075A-100000@tortoise"
charset="US-ASCII"
expires="-1"

To:w3c-wai-gl@w3.org



   Use features that enable activation of page elements via input devices
   other than a pointing device (e.g., keyboard, voice, etc.).

  Interaction with a document must not depend on a particular input
  device such as a mouse. If, for example, a form control can only be
  activated with a mouse or other pointing device, someone who is using
  the page without sight, with voice input, or with a keyboard or who is
  using an input device other than a mouse will not be able to use the
  form.

I think this passage needs to be qualified or clarified. Some voice input
systems (e.g., NaturallySpeaking and DragonDictate) include a
voice-activated mouse emulator. Other speech recognition products
(ViaVoice and VoiceXpress) lack this feature (at least for now). 

A mouse-activated form control may be perfectly accessible to someone
using one voice input product, but not another. I suggest that this
passage be rewritten to reflect more accurately the current state of
speech recognition technology. For example: 

If, for example, a form control is designed to be activated with a mouse
or other pointing device, the control may be unusable by someone who
cannot see the pointer or operate a mouse; or who uses keyboard-only
techniques, dictation software, or an input device that does not emulate a
mouse. 

"Dictation software" is my (provisional!) way to distinguish between (1)
products that are designed primarily for inputting text and (2) products
that are good for inputting text AND controlling the PC. (This dichotomy
is a bit facile, but I hope you find it useful.)

Alan Cantor
EOWG



