docno="lists-067-13190296"
received="Thu Aug 17 16:06:54 2000"
isoreceived="20000817200654"
sent="Thu, 17 Aug 2000 12:54:18 -0700"
isosent="20000817195418"
name="Kynn Bartlett"
email="kynn-edapta@idyllmtn.com"
subject="Re: literacy?"
id="4.2.0.58.20000817124701.00ae8cc0@garth.idyllmtn.com"
charset="us-ascii"
inreplyto="399B67FD.A5EAC7EB&#64;w3.org"
expires="-1"


To: Ian Jacobs<ij@w3.org>
Cc:love26@gorge.net, gl<w3c-wai-gl@w3.org>

At 09:20 PM 8/16/2000 , Ian Jacobs wrote:
>Thus, I think the emphasis on text is not strictly bound to
>assumptions of literacy but requirements to reach eyes, ears,
>and fingertips.

That's technology-specific, right?  The fact that screenreaders
exist and braille terminals exist is what lets us "use text"
and assume that it will be presented somehow to people who can't
see, yes?

If screenreaders didn't exist -- would we need to provide an
audio stream with each web page?  (A serious question, because
it deals with the evolution of technology and availability of
that technology to various groups.  If we want to be completely
technology-agnostic, we'll need to consider these things.)

Here's an example -- I work with a fellow (Jack Berkowitz) who
used to work with DARPA projects.  One of the things he's seen
was a very sophisticated image recognition program that could
look at a picture and tell you, for example, "this is an image
of a man standing next to a tree, and a van is driving by."
It could tell you what the man is wearing, what the text on
the van says, and what kind of tree it is.  (This is all stuff
used for spy satellites and whatnot.)

Now, of course, that kind of technology is not readily available.
It won't be used by the common consumer for some time.  However,
with increases in processing power for basic machines continuing
to go up, and with high technology routinely trickling down out
of the research labs, there's a possibility that within 10 years
all of us could have such a thing on our desktop machines.

This would mean that labelling images _may no longer be necessary_
at least not as we know it today.  With today's technology you
could probably set up something to read most text off of navigation
buttons using OCR.  Longdescs?  Heck, with the stuff I've described,
you can pull information out of pictures without needing a longdesc.

So the "poster child" for web accessibility -- the ALT attribute --
may not be necessary in the future.

Will this affect our "principles"?

-- 
Kynn Bartlett  <kynn@idyllmtn.com>                       http://kynn.com/
Director of Accessibility, Edapta                  http://www.edapta.com/
Chief Technologist, Idyll Mountain Internet      http://www.idyllmtn.com/
AWARE Center Director                         http://www.awarecenter.org/
Vote for Liz for N. Am. ICANN Nominee!        http://www.khyri.com/icann/



