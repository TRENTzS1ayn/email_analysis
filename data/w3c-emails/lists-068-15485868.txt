docno="lists-068-15485868"
received="Tue Mar 13 12:28:28 2001"
isoreceived="20010313172828"
sent="Tue, 13 Mar 2001 12:49:05 -0500"
isosent="20010313174905"
name="Al Gilman"
email="asgilman@iamdigex.net"
subject="What semantics?  [was: Re: distraction:  bane or content?]"
id="Version.32.20010313103859.04305e70@pop.iamdigex.net"
charset="iso-8859-1"
inreplyto="4.3.2.7.2.20010313082954.01f4d180&#64;pop3.concentric.net"
expires="-1"


To:"Leonard R. Kasday"<kasday@acm.org>, Kynn Bartlett<kynn-edapta@idyllmtn.com>, Marja-Riitta Koivunen<marja@w3.org>, Charles McCathieNevile<charles@w3.org>
Cc: WAI<w3c-wai-gl@w3.org>

I believe that it is possible to come up with readily implemented methods of
evaluating for 'enough' semantics.  That is, if we define 'enough' as some
finite body of knowledge that makes a genuine contribution and for which we
can
implement effective checks.  These checks are generally machine-assisted, but
not in general something that the machine can do on its own.

In particular, getting the author to review and approve some varied
presentations as "equivalent enough" to satisfy them.? This is what I
anticipate as the way a device independent development environment will
have to
work for profit-critical content that will be served both by interactive voice
response and by all-voice portal, for example.? I am confident that the
content
producer's standards for what is "equivalent enough" exceed the minimums
necessary for users to sustain continuity of operation in their browsing
cycle.

In fact, the level of semantics required to support graceful transformation in
the User Agent is pretty crude, and we need to be getting about articulating
what the crude discriminants are.? For example, in a
device-independent-service
resource base, we will need to know the sensory mode compatibilities of the
retained objects.? Can this object be rendered visually, and comprehended as
visually rendered?? Can it be rendered auditorily and comprehended from that
rendering?? Etc.? Does this object have a feasible alternative?? What is it?

Those things need to be known.

They need to be implemented early, in the data management policies of the
content store in the content development environment.

The cents-off coupon scenario is an old thread that passed on WebWatch.? In
this there was a retail merchant that put an image of the newspaper version of
a discount coupon on their website.? On the one hand it was argued that this
was presenting a discount in a way that excluded the blind users of the
website.? On the other hand, it was argued that all the merchant had from
their
advertising agency was the image version of what went in the paper, and that
reconstructing the text was an undue burden.

Now, in this community I am preaching to the choir about images of text.? But
in printing the newspaper that is what one uses.? So, to make the text view of
the cents-off coupon something that is readily implementable for the merchant,
their advertising agency has to be running with a resource manager that knows
it shouldn't trash the text so long as that object is live.? And if the
discount is available in the store, the object is live.? To get the web to
contain the text as well as the facsimile of the newspaper, we have to reform
the data management at the point the text is converted to image for the
newspaper.

The rules in this object management system have to be simple to be implemented
across all sorts of advertising tool suites.

There are no technical obstacles to implementing this level of semantics.? And
it would be effective in relieving access problems.? But it is "a small matter
of programming," that is to say no small effort.? We have to simplify our
message so it is easy to implement in many different content preparation
environments, and in workflow networks with dissimilar tools at different
stages in the content pipeline.? And then we need to promote it systematically
and persistently.? But to sell the actual practice that is needed to make
access the prevailing reality, we do have to pound on our message mercilessly
to simplify it as best we can.

I agree with Len on the feasibility of coming up with implementable methods
for
pure semantics or absolute device independence.

Absolute semantics and absolute device independence are simple in that they
are
easy to say.? On the other hand, they are terminally elusive in terms of
implementation.? We need to compromise and adopt an intermediate level of
generality.? Capture a level of understanding which is coarse relative to how
the content creator views their own work; but still enough to guide the user
and their agent through what choices there are in the generation of
alternative
views of the content.

I am inclined to believe that we can come up with a collection of
properties of
content objects, and connections among them, that will let us know when an
alternative is required and when such is available; and which will support
readily implementable content control methods in the user agent that achive
the
"presentation in accordance with the user's needs and preferences."? In
fact, I
would inivite all of you to review the content control modules in SMIL 2.0 and
the content control checkpoints (under guideline 2) in the User Agent
Accessibility Guidelines.? This represents the status quo in terms of a
content
information model and an operational model of presentation or view control by
the user.

In particular, I wish to warn people about the use of 'presentation' in the
current language that Len quotes.? We will do better if we think about content
control and conditional content.? In multimedia scenarios, content that is not
elected is often not recovered from the server.? There are even desires to be
able to seek within a stream and save the communication capacity that would
have been used to communicate the content skipped over.? So there is a logical
web of content available to the user interaction process at the user
interface,
and the chunking and buffering of data is an implementation detail which is
not
directly part of assuring that the choices needed by the user are available to
the user. 

In particular, note that the actual current uses of metadata are a lot about
_conditional retrieval_ of content.? This is why people put META KEYWORDS in
their web pages, so that search engines will pull up the page for people who
want the information.? And they use META SUMMARY so that the engine will
present their resource well, and people will select their page from among the
many search hits found.? Taking a conditional content view of what we want
content providers to do in the are of "know your resources" will help us
get to
an effective pattern of author, repository, and browser practices that will
deliver accessible content most of the time, rather than as an exception.? We
should build our semantic practices as an extension of what already works in
the community today.

Al

At 08:51 AM 2001-03-13 -0500, Leonard R. Kasday wrote: 
>
> My two cents in this...
>
> I don't think it's possible to provide pure semantics.? For example, here
are
> some different presentations of the same underlying semantic content:
>
> 1. [in English] The pencil is on the table.
> 2. [in German] Der Bleistift ist auf der Tabelle.
>
> or
>
> 3 [imagine a picture of a pencil on a table]
> 4.[imagine an interactive game where you look for a pencil by shooting
flares
> into a room, and you see a glimse of the pencil when you get close]
> 5. [imagine a movie where you see somebody put a pencil on a table and walk
> away.? You know, or at least assume, that the pencil is still on the table
> even after the table is out of view]
>
> The semantic content is something more abstract that we can't write down.?
> All we can write down are different representations.?? 
>
> I think the wording of the current WCAG 2.0 guidelines avoids this problem,
> e.g.
> "Design content that allows presentation according to the user's needs and
> preferences "
>
> That way of phrasing it focuses on presentation and allows us to address
user
> needs without getting into the philisophical complications of providing pure
> semantics.?? 
>
>
> Len
>
>
>
> At 03:56 PM 3/12/01 +0100, Kynn Bartlett wrote:
>>
>> At 10:41 PM -0500 3/11/01, Marja-Riitta Koivunen wrote:
>>>
>>> Authors could provide enough semantic information so that users don't have
>>> to rely on visual presentation. And when they do provide the semantics it
>>> also becomes easier to change the presentation with stylesheets.
>>
>>
>> I get worried about statements regarding "enough" semantic information
>> since I think it's a chimera that's impossible to catch or even
>> define.? Even "enough semantic information so that users don't have
>> to rely on visual presentation" is very, very hard to do, when you
>> start examining it.
>>
>> I worry about a proliferation of "semanticism" causing a huge increase
>> in the amount markup that must be produced, the number of tags or
>> attributes that must be managed, the complexity required of the author
>> when creating the content, and the requirements for user agents to be
>> able to process this information.? It's a black hole that's very easy
>> to get sucked into and like most black holes there are few easy ways
>> out of such a pit.
>>
>> (I'm not against the idea of embedding semantics, when possible, into
>> markup -- but I just get very scared by statements that we must have
>> "complete" or "enough" semantics for user agents to fully manage the
>> presentation on a semantic level.? I don't see it "working" nor do I
>> see it as necessarily being desirable to the majority of web users
>> and content providers.)
>>
>> -- 
>> Kynn Bartlett <kynn@idyllmtn.com>
>> <http://www.kynn.com/>http://www.kynn.com/
>
>
> -- 
> Leonard R. Kasday, Ph.D.??????? 
> Institute on Disabilities/UAP and Dept. of Electrical Engineering at Temple
> University
> (215) 204-2247 (voice)???????????????? (800) 750-7428 (TTY)???????? 
> <mailto:kasday@acm.org>http://astro.temple.edu/~kasday%a0%a0%a0%a0%a0%a0%a0
> mailto:kasday@acm.org 
>
> Chair, W3C Web Accessibility Initiative Evaluation and Repair Tools Group
> <http://www.w3.org/WAI/ER/IG/>http://www.w3.org/WAI/ER/IG/
>
> The WAVE web page accessibility evaluation assistant:
>
> <http://www.temple.edu/inst_disabilities/piat/wave/>http://www.temple.edu/
> inst_disabilities/piat/wave/ 



