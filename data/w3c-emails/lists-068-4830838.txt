docno="lists-068-4830838"
received="Thu Dec 28 17:41:56 2000"
isoreceived="20001228224156"
sent="Thu, 28 Dec 2000 14:41:41 -0800"
isosent="20001228224141"
name="Matt May"
email="mcmay@bestkungfu.com"
subject="Re: Question on abbreviations (fwd)"
id="01cd01c0711f$68f55f90$6401a8c0@sttln1.wa.home.com"
charset="iso-8859-1"
inreplyto="3.0.5.32.20001228164222.007c4770&#64;apembert.pop.crosslink.net"
expires="-1"


To:"Anne Pemberton"<apembert@crosslink.net>
Cc:"WAI GL"<w3c-wai-gl@w3.org>


----- Original Message -----
From: "Anne Pemberton" <apembert@crosslink.net>
> Not really. The American news outlets are capable of undertanding that the
> web needs different rules than print. Because of the interactive
> capabilities of the web, the AP style may need to be adapted for the web.

I think you grossly overestimate both the capabilities and the technical
savvy of the average American media source. The basics of many online
versions of newspapers involves scraping what went to press and wrapping it
in HTML (which means, in many cases, replace newlines with <p>, and subhead
markup with <b>). That's it, and that's all their technology will really
afford them. News organizations are on my top five list (along with grocery
stores... :) of companies that are content to make do for decades with
whatever technology they've got. In many places, content repurposing in this
manner can't be done, economically or technically (what passes for content
management software in many places is ancient stuff). In others, it just
won't.

> In response to your comment in the next paragraph, NO American news outlet
> should be defining their audience as exclusively American. This is the
> "World Wide Web", not the American Web.

That's something you'll have to take up with individual publishers. Those I
know, who collect money from advertisers and subscribers only in their area,
would disagree with you.

This, I think, is yet another argument for putting it in the user agent:
then, the user would be the one who determines when something needs to be
defined ("pull"), rather than the content provider having to prepare for
every possible audience and contingency, and potentially leaving a mess of
poorly-defined terms strewn about ("push"). Explicitly linking to
definitions is still pushing content.

> >I'm mostly here with you. But I see problems with putting the onus on
> >content providers to define already well-defined terms.
>
> On the contrary, I feel it is exactly the content providers who should
> define their terms. If the terms are already well-defined, all that is
> needed is a link to the author's favorite dictionary, or if less
> well-defined, a specialized dictionary.

If they're well-defined, why even put it on the content provider to create
that link when it's not necessary?

Next problem:
Say I link to my terms at m-w.com. They've already changed their CGI once.
If they do it again, all my definitions are dead links. Again, putting it on
the user-agent level eliminates this problem.

>  The solution I see
> >is a user-agent enhancement that lets users tie their own dictionaries,
> >online or integrated, into the agent. They can create a trusted authority
> >for defining terms, which could be overridden by the ABBR or ACRONYM tags
in
> >HTML, for example, to provide a list of possible definitions. Then, WCAG
can
> >state that content providers are only responsible for defining terms they
> >introduce or use uniquely.
>
> Ah, dumping the responsibility onto the user. Nice play! <grin> ...

Not the user. The user agent. Big difference there.

> Seriously, your description of the "trusted authority for defining terms"
> took me back a decade to when I was a member of a panel examining an issue
> of "book banning" at the school where I worked. The representative of the
> clergy maintain, among other things, that he only "recognized" as
> authoritative, a 19th century Webster version of the dictionary. The issue
> was, interestingly, an expanded acrynym ... RTFM ... used in a book, The
> Cuckoo's Egg which was supposed to be more fact than fiction about the
> early Internet. The expansion, as a footnote on page 5, used the old
> English "F" word to describe the Manual ... the only occurance of the word
> (or any other inappropriate word) in the whole book! The reverend with the
> narrow references won the day, the book was banned for classroom use, I
was
> personally vilified from the guy's pulpit for a few weeks.

All the more reason to let the user choose his or her trusted resource.

> >The potential for proliferation of untrusted definitions, which may
> >ultimately be made useless by such a system (if they're not useless to
begin
> >with), gives me pause. Do we really want to tell people to search and
> >replace all their acronyms and abbreviations, and then once a system like
> >this comes along, say, never mind, just put it back the way it was?
>
> What do you mean by "put it back"? Once the terms are marked up, they can
> be updated to newer technology. It's the unmarked up stuff that's the
> problem, not the stuff that is linked one place, and can later be moved to
> another.

My main issue is with using search-and-replace as a solution to anything.
Are the webmasters at IBM going to look at a list of guidelines and say,
"gosh, we've got 30 gigs of content, not counting everything in our
knowledge bases, most of which contain all kinds of acronyms and
abbreviations, some of which are duplicated or usage-sensitive... yeah, go
ahead and run that sed script"? Negative!

Now think about places other than plain-old markup where content can hide:
in content management systems, ASP/JSP/CGI code, Oracle databases (both
web-specific and multipurpose)... it appears to me that the dangers of
search and replace are not being considered here.



