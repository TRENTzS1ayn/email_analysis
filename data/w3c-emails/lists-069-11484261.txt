docno="lists-069-11484261"
received="Wed Apr 17 14:10:38 2002"
isoreceived="20020417181038"
sent="Wed, 17 Apr 2002 13:10:27 -0500"
isosent="20020417181027"
name="john_slatin"
email="john_slatin@forum.utexas.edu"
subject="RE: html code element and speech output"
id="6AC4E20EED49D411941400D0B77E52F0069397E1@forum.cc.utexas.edu"
inreplyto="html code element and speech output"
expires="-1"


To:"'Charles McCathieNevile'"<charles@w3.org>,"'Gregory J. Rosmaita'"<unagi69@concentric.net>
Cc:"'Wendy A Chisholm'"<wendy@w3.org>,"'w3c-wai-gl@w3.org'"<w3c-wai-gl@w3.org>

*Is* there a tool that supports SSML? I'd love to play with it.  Use it,
even, if it actually works.  (I'm not a UNIX person, if that makes a
difference.)

John

-----Original Message-----
From: Charles McCathieNevile [mailto:charles@w3.org] 
Sent: Wednesday, April 17, 2002 10:20 am
To: Gregory J. Rosmaita
Cc: Wendy A Chisholm; w3c-wai-gl@w3.org
Subject: Re: html code element and speech output


Another approach to using ACSS in tools would be to convert the document to
XHTML, and then to turn it into an intermediate XML through the use of local
javascript, and then to convert that to Speech Synthesis Markup Language
(SSML) through the use of XSLT, and find a tool that uses this new language
(being developed as part of the Voice Browser work at W3C.

As Joe pointed out, messing around a user's speech setup is a pretty bad
idea in general, so it makes sense to use careful styling based on
well-described types of objects rather than just assiging style to each
element. This gives the user the easiest path to override a style and
provide their own. It would also be helpful if, there were good editors for
CSS available that handled audio style sheets by example rather than by
making the user learn the code to write. (this applies to visual properties
too...)

Chaals

On Tue, 16 Apr 2002, Gregory J. Rosmaita wrote:

  aloha, wendy!

  as you know, i'm not quite up to snuff on the real world, but i can tell
  you that you can define any number of aural properties for CODE using the
  speaking properties defined in section 19 of the CSS2
  specification...  most germane are the speech properties
  "speak-punctuation" and "speak-numeral" which are defined in section 19.9,
  as follows:

  <quote href="http://www.w3.org/TR/CSS2/aural.html#speech-props">
  19.9 Speech properties: 'speak-punctuation' and 'speak-numeral'

  An additional speech property, speak-header, is described in the chapter
on
  tables

  'speak-punctuation'

  Value: code | none | inherit
  Initial: none
  Applies to: all elements
  Inherited: yes
  Percentages: N/A
  Media: aural

  This property specifies how punctuation is spoken. Values have the
  following meanings:

  code
  Punctuation such as semicolons, braces, and so on are to be spoken
literally.

  none
  Punctuation is not to be spoken, but instead rendered naturally as various
  pauses.
  </quote>

  here's an example of how one might use CSS2 to have an aural-CSS-aware
  browser indicate items marked-up using the CODE element:

  <example>
  @media aural {
  code { voice-family: robot, male;
           speak-punctuation: code;
           speak-numeral: digits; }
  }
   >/example>

  note 1: i defined 2 values for voice-family (1) a specific-voice value and
  (2) a generic-voice value; - what i'd really like to do is  be able to
  define inverse relationships, so that, for example, if a user had the
aural
  browser's default voice set to "female", when the UA encountered the CODE
  element, it would aurally "reverse fields" and speak the text marked up as
  CODE in a "male" voice -- obviously, this would be handy in other (mostly?
  exclusively?) binary situations, as well as an ideal way to ensure that
  changes in background and/or foreground color don't collide with client
  side settings (in other words, simply reverse the "color:" and
  "background:" values when rendering a block marked as "foo" or defined by
  the FOO element)

  note 2: one could use a host of other aural properties to aurally
demarcate
  CODE...a simple pitch change, for example, or a cue-before and cue-after
  event, or a change in the voice characteristics values, such as stress or
  richness...  note that what are generally classed as "synthesized voices"
  are pre-set combinations of voice characteristics - for more details on
all
  this jargon, consult the URI cited above...

  of course, only an aural-CSS-aware client/application would provide the
  desired aural effect (a voice change) when encountering this example
  markup, although providing the desired effect (a simple voice
  characteristic change) as the result of a DOM call is not only possible,
  but essential, in my opinion -- assistive software needs to be aware of
the
  UA's generic values (defined in the base style sheet, which for most
users,
  if not in most browsers, is immutable) and provide analagous values in
  whatever output modality is required...  wherever generic classes have
been
  defined by the UA (such as for CODE, Q, KBD, SAMP, etc.) an AT needs to
  provide a means of identifying those classes, as well as controlling the
  means of identification -- think of it as equivalent content, for the
  default rendering of CODE as monotype IS content!

  of course, there are also low-tech solutions to the problem, such as
screen
  scraping, but they are not as efficient nor can they ever be as
  interoperable as an AT that is not only DOM-aware, but CSS-aware...

  just my 2 cents, american, as someone who mostly uses IE6 or lynx in
  conjunction with JAWS 4.02, from which no aural indication of
  content-related elements is obtainable, gregory.

  At 03:27 PM 4/16/02 -0400, you wrote:
  >Hello,
  >
  >Could someone tell me if Jaws, Window Eyes, Home Page Reader, et al give
  >some indication when html code elements have been encountered?
  >
  >e.g. here's a code snippet
  >
  >here's some text
  >here's some code
  >When "here's some code" is read - does it give indication that this is
  >code?  Visually, it is usually shown in a courier font (to make it look
  >more machine-like i suppose).  Just wondering if there is also some audio
  >indication.
  >
  >Could you please include the version and platform of the product that you
  >are using?
  >
  >Thanks,
  >--wendy
  >
  >--
  >wendy a chisholm
  >world wide web consortium
  >web accessibility initiative
  >seattle, wa usa
  >/--

  ------------------------------------------------------------------
  The trouble with the world is that the stupid are cocksure and the
  intelligent are full of doubt.                 -- Bertrand Russell
  ------------------------------------------------------------------
              Gregory J. Rosmaita <unagi69@concentric.net>
  Camera Obscura:           http://www.hicom.net/~oedipus/index.html
  VICUG NYC:          http://www.hicom.net/~oedipus/vicug/index.html
  Read 'Em & Speak:   http://www.hicom.net/~oedipus/books/index.html
  ------------------------------------------------------------------



-- 
Charles McCathieNevile    http://www.w3.org/People/Charles  phone: +61 409
134 136
W3C Web Accessibility Initiative     http://www.w3.org/WAI  fax: +33 4 92 38
78 22
Location: 21 Mitchell street FOOTSCRAY Vic 3011, Australia
(or W3C INRIA, Route des Lucioles, BP 93, 06902 Sophia Antipolis Cedex,
France)



