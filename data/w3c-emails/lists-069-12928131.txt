docno="lists-069-12928131"
received="Mon May  6 12:30:01 2002"
isoreceived="20020506163001"
sent="Mon, 06 May 2002 11:29:53 -0500"
isosent="20020506162953"
name="Gregg Vanderheiden"
email="GV@TRACE.WISC.EDU"
subject="RE: 2.1 thoughts"
id="004801c1f51b$40856290$ce17a8c0@laptop600"
charset="us-ascii"
inreplyto="Pine.LNX.4.30.0205021955560.9466-100000&#64;tux.w3.org"
expires="-1"

To:w3c-wai-gl@w3.org


Chaals wrote

> this starts to make sense, but I don't like it - it should be possible
in
> most cases to just use a mouse to drive everything, yet that doesn't
seem to
> be supported here.

Question,
How would you enter text with a mouse?    
(Using an on screen keyboard doesn't count since that is a keyboard as
far as the application is concerned). 



ALSO Chaals wrote

>   5.All functionality operable via text input plus tab, up, down,
>   left, right, and enter.

>   (these are the text and command keys that can be ensured would be on
all
>   "keyboards"  (real or virtual).)
> 
> No they are not. One of my two keyboards doesn't have this. And
speech-based
> systems don't have up, down, left, right as ways of relating things.
This is
> too specific to visual environments.

3 Questions
1- Which keys were missing.  The arrowkeys?

2 - What speech input system doesn't provide a way to operate keyboard
keys?  (One on a system without a keyboard?)

3 - How about 
--- Text input plus  "step to next" (TAB) and "Activate". (ENTER).
The arrowkeys can be optional but all function needs to be operable with
text and the two functions.



Gregg

------------------------------------
Gregg Vanderheiden Ph.D.
Ind Engr - Biomed - Trace,  Univ of Wis
gv@trace.wisc.edu

 

> -----Original Message-----
> From: Charles McCathieNevile [mailto:charles@w3.org]
> Sent: Thursday, May 02, 2002 7:02 PM
> To: Gregg Vanderheiden
> Cc: w3c-wai-gl@w3.org
> Subject: Re: 2.1 thoughts
> 
> On Thu, 2 May 2002, Gregg Vanderheiden wrote:
> 
>   Some of the approaches from that
> 
> 
>   1.Operable with device independent handlers
> 
>   -          does this include text input?
>   -          what are these?
>   -          do they apply to all technologies?
>   -          Would they all be operable from keyboard?
> 
> I think this is important. There has been some discussion in the User
agent
> group about how to use DOM 2 to provide device independent handlers -
> essentially the user agent decides what triggers to give, and can be
> configured. character input is one approach to triggering them,
> mouse/keyboard commands and menus is another.
> 
> 
> 
>   2.Operable from Keyboard
> 
>   -          assumes all devices have a keyboard?
>   -          what keys on keyboard?  (function keys too)?
> 
> This is too general (what keys, is there a keydown/keyup function?
etc) and
> too specific - not all devices have a keyboard, and many have only a
very
> small one.
> 
>   3.All functionality is operable using event handlers that can be
>   activated with commands.
> 
>   -          can text be input with commands?
>   -          What does commands mean?
> 
> This just seems a bit vague on what it really means.
> 
>   4.All functionality is operable via text input plus command
>   operable events
> 
> this starts to make sense, but I don't like it - it should be possible
in
> most cases to just use a mouse to drive everything, yet that doesn't
seem to
> be supported here.
> 
>   5.All functionality operable via text input plus tab, up, down,
>   left, right, and enter.
> 
>   (these are the text and command keys that can be ensured would be on
all
>   "keyboards"  (real or virtual).)
> 
> No they are not. One of my two keyboards doesn't have this. And
speech-based
> systems don't have up, down, left, right as ways of relating things.
This is
> too specific to visual environments.
> 
> just my 2c worth
> 
> chaals



