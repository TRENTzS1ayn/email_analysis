docno="lists-070-10663478"
received="Tue Nov 12 12:30:17 2002"
isoreceived="20021112173017"
sent="Tue, 12 Nov 2002 08:30:46 -0900"
isosent="20021112173046"
name="Doyle"
email="dburnett@sesa.org"
subject="Re: Level 3 success criteria for checkpoint 1.2 (UPDATED per discussion at  11/7 meeting)"
id="B9F66CB6.2400%dburnett@sesa.org"
charset="US-ASCII"
inreplyto="000f01c28750$4da41e90$ef117b81&#64;Spot"
expires="-1"

To: Paul Bohman<paulb@cpd2.usu.edu>,"'Andi Snow-Weaver'"<andisnow@us.ibm.com>,<w3c-wai-gl@w3.org>



Good Morning From Icy Anchorage

Anyway, to follow-up on our on-going discussion of simultaneous events
related to captioning of video, I did locate one bit of research that refers
to, "Time Spent Viewing Captions On Television Programs", American Annals of
the Deaf, Volume 145 #5 (if anyone wants the full citing, let me know).

Although this research does not look at some of the specifics we were
addressing, it does look at the amount of time a deaf user spends looking at
visual content vs. captions and off screen events (looking away for some
reason). There were no differences between age group, sexes or types of
programming (type of television program).

In short, 82% of a viewers time was spent focusing on captions (true for all
in study).  When the caption speed was increased, the time spent on captions
went up to 86%.  2% of the time, those researched gazed off screen.

I know this does not really address the full issue we were discussing but
maybe this will be helpful as we continue our dialogue.  In essence, those
of us who are blind or sighted can listen to certain types of audio/visual
material and gather quite a bit of what happened without seeing the screen
while a deaf individual must be glued to the screen at least 86% of the time
to gather the same information.  Guess this means they need a runner to go
grab them a cold beer...kidding!

Anyway, hope this is a little helpful
 
-- 
Doyle Burnett
Education Specialist
Multiple Disabilities Program
907-562-7372
> From: "Paul Bohman" <paulb@cpd2.usu.edu>
> Date: Fri, 8 Nov 2002 10:57:28 -0700
> To: "'Andi Snow-Weaver'" <andisnow@us.ibm.com>, <w3c-wai-gl@w3.org>
> Subject: RE: Level 3 success criteria for checkpoint 1.2 (UPDATED per
> discussion at  11/7 meeting)
> Resent-From: w3c-wai-gl@w3.org
> Resent-Date: Fri, 8 Nov 2002 12:57:35 -0500 (EST)
> 
> 
> The concerns that Joe brought up about simultaneous captions and other
> visual content are valid concerns. Most of the time, captions can be
> viewed at the same time as the other events on the screen without too
> much difficulty, especially with practice.
> 
> There are some cases where there may be some legitimate conflicts. For
> example, if the screen shows a lengthy list of sports scores at the same
> time that a voice in the background is explaining something (and not
> just reading the text on the screen), this could be difficult to follow.
> The viewer's attention would be divided between the captions and the
> other text on the screen.
> 
> Still, as Joe pointed out, the norm right now for captioning would be to
> allow the captioning to proceed even if there is a potential visual
> conflict, requiring the viewer to pay attention to both the captions and
> the other visual elements simultaneously. It would be difficult for the
> WAI to require that all broadcasts be adapted from their original format
> to insert pauses where there may be a conflict with captioning and other
> visual elements. And it would be impossible to implement such pauses in
> live broadcasts. In fact, to truly implement this success criterion,
> directors, actors and script writers would have to change their
> procedures. The chef (to use the example from the previous message)
> would have to change her behavior. She would have to make sure that she
> explains nothing while performing the actions, and that she fully
> explains the actions either before or after performing them.
> 
> But, as it stands right now, this is a Level 3 success criterion.
> Captioners would not be required to implement this technique at either
> the Minimum level or Level 2. Maybe we are justified in keeping this
> success criterion based on that fact alone, however...
> 
> The real question is whether such a technique would be beneficial to
> users with disabilities. The user group that may benefit most may be
> those with cognitive disabilities, but this is just a guess. I don't
> personally know of any research in this area (though it may exist) which
> suggests that it would be better to not provide captions while something
> important is happening elsewhere on the screen. If research exists, and
> if this conclusion is accurate, then it would be wise to keep this
> success criterion in the guidelines at Level 3. If there is no body of
> research in that area, or if the research is inconclusive, I would
> recommend removing the success criterion.
> 
> I say this because I can imagine one set of experts arguing that it is
> actually *better* to provide the explanation simultaneously with the
> demonstration (as in the chef example). I tend to think that it would be
> better for me if the visual demonstration and the verbal explanation
> occurred at the same time, even if it does require me to view captions
> and the visual demonstration simultaneously. I haven't researched this
> myself. I am only postulating, but if no one else has any solid research
> either, it may be better to leave this one out of the guidelines.
> 
> Paul Bohman
> Technology Coordinator
> WebAIM (Web Accessibility in Mind)
> www.webaim.org
> Center for Persons with Disabilities
> www.cpd.usu.edu
> Utah State University
> www.usu.edu 
> 
> 
> -----Original Message-----
> From: w3c-wai-gl-request@w3.org [mailto:w3c-wai-gl-request@w3.org] On
> Behalf Of Andi Snow-Weaver
> Sent: Friday, November 08, 2002 10:19 AM
> To: w3c-wai-gl@w3.org
> Subject: Re: Level 3 success criteria for checkpoint 1.2 (UPDATED per
> discussion at 11/7 meeting)
> 
> 
> 
> Amended as per discussion at yesterday's call:
> 
> Level 3 success criteria
> 
> 3. The presentation does not require the user to view captions and the
> visual presentation simultaneously in order to understand the content.
> 
> and the modified informative example would be...
> 
> A cooking video shows a chef preparing a recipe. The chef describes the
> ingredients and the process for each step and then performs the step. In
> this manner, deaf users can read the voice captions first and then watch
> the demonstration.
> 
> Andi
> andisnow@us.ibm.com
> IBM Accessibility Center
> (512) 838-9903, http://www.ibm.com/able
> Internal Tie Line 678-9903, http://w3.austin.ibm.com/~snsinfo
> 
> 
> 
> 



