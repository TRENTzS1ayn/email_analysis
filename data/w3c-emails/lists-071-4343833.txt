docno="lists-071-4343833"
received="Sun Mar  9 02:09:11 2003"
isoreceived="20030309070911"
sent="Sun, 09 Mar 2003 01:09:04 -0600"
isosent="20030309070904"
name="Gregg Vanderheiden"
email="gv@trace.wisc.edu"
subject="RE: Device Independence"
id="005301c2e60a$c64fdfa0$046fa8c0@TOSHIBATABLET"
charset="US-ASCII"
inreplyto="00a701c2e5d2$b5587000$5f814094&#64;rose"
expires="-1"

To:"'Lee Roberts'"<leeroberts@roserockdesign.com>,w3c-wai-gl@w3.org


Hi Lee,

 

Yes- That is exactly why the proposal says keyboard or keyboard interface.
Speech recognition programs interface with standard programs by looking like
a keyboard.    I don't know of any voice products that interface with
standard programs that can't appear to the program exactly like keystrokes.
Some also have other interfaces to particular popular programs and mouse
emulation too, but all are able to "type keystrokes" that look like the came
from the keyboard.   

 

 
Gregg

 -- ------------------------------ 
Gregg C Vanderheiden Ph.D. 
Professor - Ind. Engr. & BioMed Engr.
Director - Trace R & D Center 
University of Wisconsin-Madison 

-----Original Message-----
From: Lee Roberts [mailto:leeroberts@roserockdesign.com] 
Sent: Saturday, March 08, 2003 6:28 PM
To: gv@trace.wisc.edu; w3c-wai-gl@w3.org
Subject: RE: Device Independence

 

Gregg,

Yes, that promotes the use of other devices and does lay the base
requirement to keyboard or keyboard-like inputs.  The base should always be
keyboard or keyboard-like devices and I do agree.  My concern was people
tend to ignore other devices if we declare only one type of device.

 

A quadriplegic (sorry about the spelling) may not have the use of a
blow-stick or other click device and only have access to a speech
recognition program.  The inputs from that program wouldn't be keyboard or
keyboard-like.  I hope this helps clarify my concerns.

 

Thanks,

Lee

-----Original Message-----
From: Gregg Vanderheiden [mailto:gv@trace.wisc.edu] 
Sent: Saturday, March 08, 2003 2:21 PM
To: 'Lee Roberts'; w3c-wai-gl@w3.org
Subject: RE: Device Independence

Hi Lee.

 

I understand the first part about not using Mouseover etc. and agree.  And I
believe that would be met by what was proposed. (e.g. must be operable from
keyboard).

 

I don't understand  your second part about not wanting things to be keyboard
only.  

 

The proposal just says it must be keyboard operable.  Not that you can't
have it do other things as well.   I presume you don't want to lose keyboard
operability in favor of other things (i.e. mouse only or pointer only").  So
are you just asking that it be written so that it doesn't sound like
Keyboard only?

 

Does the following meet your requirement/concern?

 

 "All content functionality must be usable by (from?) a keyboard or keyboard
interface if the function or its result can be concisely expressed in words.


NOTE: Other interface methods such as pointing can and should be supported
in parallel with keyboard operability as appropriate, but keyboard operation
is always required for functionality whose name or result can be concisely
expressed in words."

 

Thanks 


Gregg

 -- ------------------------------ 
Gregg C Vanderheiden Ph.D. 
Professor - Ind. Engr. & BioMed Engr.
Director - Trace R & D Center 
University of Wisconsin-Madison 

-----Original Message-----
From: w3c-wai-gl-request@w3.org [mailto:w3c-wai-gl-request@w3.org] On Behalf
Of Lee Roberts
Sent: Monday, March 03, 2003 8:34 AM
To: gv@trace.wisc.edu; 'WCAG List'
Subject: RE: Device Independence

 

My goal with "device independence" is to get people to quit using _scrap
code_ that requires a mouse to perform the functions.  All these
onmouseover, onmouseout, onclick, ondblclick, and such do not work for
everyone.  I've talked to more developers than I can count that didn't even
know onselect, onfocus, onblur existed and then wanted to know what they
were for when I explained they should be using them.

 

I don't think we should limit accessibility to just keyboard or keyboard
interfaces.  Wireless devices will provide some interesting advancements
what will likely move into the desktop arena.  One device I've seen that
could work well in computing is the same tool helicopter pilots use to aim
their canons.  With that tool, I see mouse usage going away.  

 

We don't know when the next evolution of the WCAG will be started or the
technologies available.  It should be our goal to open the door to other
technologies, so those technologies will have some guidance on how to be
used to provide accessible interfaces and content.

 

Lee

-----Original Message-----
From: w3c-wai-gl-request@w3.org [mailto:w3c-wai-gl-request@w3.org] On Behalf
Of Gregg Vanderheiden
Sent: Sunday, March 02, 2003 10:16 PM
To: 'WCAG List'
Subject: Device Independence

The term "device independence" keeps coming up.    So I would like to write
something here to spur a dialog that will let us clear this concept up as it
relates to accessibility.

 

 

 The term device independence has always been a very confusing term.    If
device independence means anything other than

 "usable by a keyboard or keyboard interface if the function or its result
can be concisely expressed in words"  

 then I do not think that we want or need it.   In fact I do not see how it
could even be possible. 

 

If the goal is to allow content to be accessed from PDAs, by Voice, by
keyboard etc. then 

"usable by a keyboard or keyboard interface if the function or its result
can be concisely expressed in words"  

will get you this.

 

If you would like to ALSO add mouse control to make some tasks easier. That
is fine.  But we should not require it - and, as I said above, I don't even
think it is possible.   

 

Since text input is sometimes required as a part of web content interaction,
it would mean that text input would have to be possible using just a mouse.
This in turn  would require that every single page that required text input
have a keyboard on the page and a  script to drive it.   If an external
on-screen keyboard is used - then you are using keyboard input to the
content - not mouse.    And if a keyboard on the page is used then you are
requiring that a script be used and the page would fail if the script did
not run.    

 

Help me here.   

 

1) what does "device independence"  mean?

 

2) independence from what?

 

3) does it require that all content be usable with a mouse only?

(if so - how could this be done?  Remember an on screen keyboard that is not
part of the content is just a keyboard and the content would be receiving
keyboard input.) 

 

4) does it require that all content be usable with a keyboard only?

 

5) does it require anything else?

 

 

How does device independence make things any more accessible than

"usable by a keyboard or keyboard interface if the function or its result
can be concisely expressed in words"  

 

(I am presuming that device independence does not mean "also support a mouse
where that is a good interface practice".   That would make the pages more
accessible but does not sound like device independence because it doesn't
make the content independent of any device or input method.   It is just
good user interface design practice that makes the page more usable).

 

Help me if you can.   Am I missing something?

 

Thanks

 


Gregg

 -- ------------------------------ 
Gregg C Vanderheiden Ph.D. 
Professor - Ind. Engr. & BioMed Engr.
Director - Trace R & D Center 
University of Wisconsin-Madison 

 



