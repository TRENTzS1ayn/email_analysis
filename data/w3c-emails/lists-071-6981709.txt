docno="lists-071-6981709"
received="Sat Aug  9 16:49:40 2003"
isoreceived="20030809204940"
sent="Sat, 9 Aug 2003 16:49:39 -0400 (EDT)"
isosent="20030809204939"
name="Charles McCathieNevile"
email="charles@w3.org"
subject="RE: [lexical (+ contextual) clarification] Re: proposal 3:   checkpoint   3.3"
id="Pine.LNX.4.55.0308091639390.11724@homer.w3.org"
charset="US-ASCII"
inreplyto="16180.37470.782426.216276&#64;jdc.local"
expires="-1"

To: Jason White<jasonw@ariel.ucs.unimelb.edu.au>
Cc: lisa seeman<seeman@netvision.net.il>, WAI GL<w3c-wai-gl@w3.org>



Interestingly it is easy to test whether something has complied by machine,
since the process essentially involves testing that the content is entirely
the things that are (and here we get vague for today) widely understood
language.

Describing a language in sufficient detail to do this is not a trivial task -
for small and restricted languages like the Yolngu Matha group from Northern
Autralia it could perhaps be done in a few years - for the Quinkan language
it is not clear that the remaining native speakers will live long enough to
permit it to be done. On the other hand, large and fluid languages like
english present a challenge of keeping the information up to date.

There are two approaches to making a dictionary (and grammar). One is that
typified by the Oxford English Dictionary, which is essentially empirical -
it seeks to record the language as it is in fact used. The second is to write
down how the language "should" be used - attempting to define good and bad
usage. In countries such as France, Spain, the Vatican, and Iceland, there
are official bodies which do this.

It strikes me that what is important for WCAG is the empirical approach to
understanding what really are commonly understood terms, rather than knwoing
what "ought to be", which is perhaps an easy way to get 80% accuracy but not
capable of providing better.

(Note that taking into account further issues such as unambiguous use of
terms complicates further in some languages. Others, like Esperanto, make
that impossible...)

cheers

Chaals

On Sat, 9 Aug 2003, Jason White wrote:

>In fact it might even be machine testable if there is a generative
>grammar for the required syntax and a list of permissible vocabulary;
>and before anybody asks, it is a fundamental insight of modern
>linguistics, as I understand it, that the syntax of every natural
>language can be described by a generative grammar.
>

Charles McCathieNevile  http://www.w3.org/People/Charles  tel: +61 409 134 136
SWAD-E http://www.w3.org/2001/sw/Europe         fax(france): +33 4 92 38 78 22
 Post:   21 Mitchell street, FOOTSCRAY Vic 3011, Australia    or
 W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France



