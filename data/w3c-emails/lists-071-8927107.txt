docno="lists-071-8927107"
received="Thu Sep  4 18:20:14 2003"
isoreceived="20030904222014"
sent="Fri, 5 Sep 2003 00:19:48 +0200"
isosent="20030904221948"
name="Y.P. Hoitink"
email="y.p.hoitink@heritas.nl"
subject="Checkpoint 3.1 - Identifying language"
id="001101c37332$aa5852e0$7b00a8c0@Adder"
charset="us-ascii"
expires="-1"

To:<w3c-wai-gl@w3.org>



Hello everyone,

I have been going through the internal working draft of the WCAG 2.0
guidelines <http://www.w3.org/WAI/GL/WCAG20/> and came across core
checkpoint 3.1 (Language of content can be programmatically determined).

The success criteria for checkpoint 3.1 reads:
"passages or fragments of text occurring within the content that are written
in a language other than the primary natural language of the content as a
whole, are identified, including specification of the language of the
passage or fragment. "

Meeting this success criteria is a heavy burden for people writing in
languages which use a lot of foreign words. For example, my native language
Dutch uses a lot of English words and phrases , like "website", "software
engineering", "content management", "on the job training" etc. On a typical
Dutch page, especially on a technical or management subject, several
percents of the words can easily be foreign. To meet this success criteria,
all of these would have to be labelled with their original language.

This isn't a problem in English so much, since there aren't so many foreign
words. I guess this is why we hear the "je ne sais quoi" example all the
time :-) But we're writing these guidelines for the entire internet, not
just the English speaking community.

I understand that labelling foreign phrases with their language would
increase accessibility. If English words are spoken out loud with Dutch
pronounciation by speech synthesizers, they are hard to understand because
the words sound quite different. 

But it is quite a lot to ask to label everything for people writing in
languages which use a lot of foreign words. Also, even though they are
harder to understand, the phrases can still be heard so it's not _totally_
inaccessible. I don't think this issue should be on the same level of
requirements as, for example, the need for text equivalents for non-text
content.

What I'm trying to say is this: Shouldn't this be a best practice instead of
a required success criteria?

On the other hand, I was surprised to find that the identification of the
_main_ language of the document is only a best practice, and not a success
criteria. So we are requiring to label every foreign phrase, but we don't
even know what the main language is? Couldn't this lead to the unwanted
situation that 99% of the document is read with the wrong pronounciation,
except for the few foreign words whose language _was_ identified? 

I have been trying to find past discussions about this in the mail archives
but haven't seen these issues. If I missed them, I would appreciate it if
someone could send me the links.

Yvette Hoitink



