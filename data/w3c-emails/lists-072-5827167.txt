docno="lists-072-5827167"
received="Tue Feb 10 09:13:36 2004"
isoreceived="20040210141336"
sent="Tue, 10 Feb 2004 14:13:10 -0000"
isosent="20040210141310"
name="Richard Ishida"
email="ishida@w3.org"
subject="RE: Summaries of issues around checkpoints 1.4 and 1.5"
id="005a01c3efe0$05c168e0$cd01000a@w3cishida"
charset="us-ascii"
inreplyto="40285DC8.2040404&#64;oracle.com"
expires="-1"

To:"'Kerstin Goldsmith'"<kerstin.goldsmith@oracle.com>,"'wcag working group'"<w3c-wai-gl@w3.org>



Sorry if my timing is bad, I just noticed this. See notes below...

> Checkpoint 1.4 from WCAG 2.0 Internal Draft (17 November 
> 2003) currently
> reads:
> "All text can be decoded into words represented in 
> Unicode." Success Criteria Level One:

I think a better way of saying this might be "All text can be decoded into
words, representable using Unicode characters."


> 1. text in the content is provided in Unicode or sufficient
> information is provided so that it can be automatically 
> mapped back to Unicode. 
> Success Criteria Level Two:
> 1. abbreviations and acronyms are clearly identified 
> each time they
> occur if they collide with a word in the standard language 
> that would also logically appear in the same case (e.g. all caps). 
> 2. symbols such as diacritic marks that are found in 
> standard usage
> of the natural language of the content, and that are 
> necessary for unambiguous identification of words, are 
> present or another standard mechanism for disambiguation is 
> provided. 


I take it that this refers to Arabic and Hebrew?  If so, 'standard usage of
the natural language of the content' is probably not appropriate, since
diacritics in these scripts are not used in standard usage.


>Success Criteria Level Three: 
> None
> 
<snip/>



