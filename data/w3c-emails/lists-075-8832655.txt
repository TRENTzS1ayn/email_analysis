docno="lists-075-8832655"
received="Mon Apr 17 09:39:41 2000"
isoreceived="20000417133941"
sent="Mon, 17 Apr 2000 09:36:13 -0400"
isosent="20000417133613"
name="Bruce Bailey"
email="bbailey@clark.net"
subject="RE: Request for site review"
id="000601bfa871$e64f7100$53fe330a@msde"
charset="iso-8859-1"
inreplyto="NDBBKJDAKKEJDCICIODLOEKICAAA.thatch&#64;attglobal.net"
expires="-1"

To:<jim@jimthatcher.com>
Cc:"Web Accessibility Initiative"<w3c-wai-ig@w3.org>


Dear Jim,

Thank you for your continue comments.

> I suppose the sub-menu popup links are a text-only idea, but I stick to
> the idea that this is both sensible and good - except for the
> serious navigation problem on the sub-menu page.

> I hold to the position that navigation on the submenu page is a
> problem, a solvable problem, but the page passes muster in my
> opinion.

I am greatly relieved that you find the page acceptable as is.

In both of your paragraphs above, by "sub-menu page" are you referring to
the onMouseOver navigation tool-tip pop-ups?

> When using menus in ordinary software, the screen reader user must
> actively say I want to see the submenu. That is the correct behavior.
> You would hate to be taken into every sub-menu as you went down a
> main menu with speech. The mouse user, on the other hand, has the
> advantage of having sub-menus appear as you move down the menu
> with the mouse, just as with sailor. Lucky him! It is imperative
> that the speech user choose to hear the submenu.
>
> As for number of steps, you indicated,
>> Current page, using onMouseOver:
>> Home Page -> onMouseOver sub-menu -> Target Page (one "click")
>> Current page, using screen reader or keyboard:
>> Home Page -> sub-menu page -> Target Page (two "clicks")
> But the mouseover must be considered an action. The user does do
> something. The number of actions is the same -
>
> Find main menu item
> bring up submenu
> find sub-menu item
> open target page
>
> Everyone must take these steps. If you can see it is easier.

I agree with your meta over-all view of this, but visually, with a mouse and
the context sensitive onMouseOver content, the two middle items happen so
fluidly (and possibly without planning and/or much thought on the part of
the user) that the operation is very condensed and feels more like one
operation than two.  The mechanics of activating the onMouseOver content is
completely contained within the "action" of selecting the original target.
In fact, the visual user has little choice but to be exposed (however
briefly) to the additional content.

One can imagine an aural agent which would sound a subtle tone or inflection
to indicate the presence of optional additional content.  Intentional
activation would be required on the part of the user for this though.  This
is in contrast to onMouseOver -- which can be discovered quite accidentally
by the visual user.  (I have the intention of selecting a link, but just as
I am about to do so, I inadvertently activate onMouseOver content which, if
I let it interrupt me for a moment, generally provides me some even better
choices.)

A visual agent (onMouseOver) provides additional content just as I am about
to select a link, but after I have read the material that allowed me to
decide that I wanted to select that link.  An aural agent (none do this as
far as I know) would have to provide cueing a little early on in this
information processing chain.



