docno="lists-076-6774532"
received="Thu Oct 19 14:29:57 2000"
isoreceived="20001019182957"
sent="Thu, 19 Oct 2000 19:29:36 +0100"
isosent="20001019182936"
name="Wayne Myers-Education"
email="wayne.myers@bbc.co.uk"
subject="belittling designers, two kinds of accessibility"
id="6F99E54D359CD3119FAF0001FA7ED9500178FB91@w12wcedxu02.wc.bbc.co.uk"
expires="-1"


To:w3c-wai-ig@w3.org

> PS: To constantly belittle those who design in 
> multi-media and graphics is
> never going to get this group anywhere close to acceptance by 
> those very
> people you are supposed to be addressing. 

Argh. Ok. Rant time. Apologies in advance...

Here's my take on the problem here, including why those who refuse to accept
certain facts about the web are always going to be belittled, and why I
believe there are two kinds of accessibility that require entirely different
approaches, but which can lead to amusing arguments-without-end between
people who conflate the two and confuse the issues.

The web is plagued by people who misunderstand it, but who nevertheless
build large parts of it.

The web is a collection of documents - in the loosest form of the term -
which are deliberately constructed in a format which is - by design -
supposed to be independent of the way in which those documents are accessed.
That is what the web is.

People who approach the web in terms of multi-media and graphics - and
nothing more - are therefore missing the point of the medium. The medium
allows people to construct documents that may or may not contain multi-media
or graphics, but where the inability to view any multi-media or graphics
does not stop them from getting the content from the document.

The fact that hordes of multi-media and graphics focussed people have
misunderstood this and have flooded the web with pages that break the rules,
tell you what screen resolution you require, tell you what kind of browser
you require, assume that all users have a certain level of bandwidth in
their connection, assume that all users can see, and so on and so on, is,
AFAIK, precisely the reason that the WAI was set up.

Sites where the content relies upon multi-media and graphics are not
websites. They are something else, and they just happen to use web
technologies to be distributed. But since they rely on highly specific
software/hardware configurations in order to be viewed, they are not
websites - whether they claim to be or not (and they usually do). People
might say that their content *is* the multi-media and the graphics. Fine.
But it's not a web document, even if it uses the web for distribution.
Personally, I prefer the multi-media and graphics you can get from real
standalone multi-media/graphics fest stuff (such as games machines) and have
yet to see a 3d environment online that came close to Quake (a popular 3d
environment action game where you run around shooting at monsters, friends,
or both). The web is the web, and Quake is Quake, and that ought to be an
end of it.

The reason that people trying to funnel something Quake-like into web pages
get belittled is that anyone working in a medium which they clearly do not
understand (by their work) is going to cause serious frustration among those
who do. In other media, there is a threshold of publishing control - of a
sort - which means that people who do not understand those media do not get
to pollute that media space with it. Someone who thinks that 1000 words is
sufficient for a novel is simply never going to get that 'novel' published
as a novel. Someone who thinks that text containing nothing but libellous
attacks and cuss-words is suitable for publication in a broadsheet newspaper
is going to find that no editor will publish them (or indeed commission them
again).

On the other hand, someone who thinks its ok to make a large executable file
requiring a specific plugin containing rotating teapots and so on and who
then sells that file to someone in the guise of a 'website', *is* going to
be able to 'publish' it. More commonly, too many seem to think it's ok to
make and sell a 'normal' website using some automatic site creation tool
which fails to ensure that the resulting site will work in any but the most
recent generation of browser software, and then focus on the 'look and feel'
of the site in those browsers, without bothering to find out what it will
look like in other browsers, on PDAs, through voice portals, screen readers
or whatever other new systems for accessing the web will have been invented
by the time I finish ranting.

Since people paying for websites - almost by definition - hardly ever have
much understanding of quite what they are paying for, rotating teapots and
the like can easily impress the people with the purse strings; as can
'normal' sites presented as flat images. This process can take business away
from people who actually do know what they are doing, and that is more than
enough grounds for any belittlement that may be going on here. Such will
continue, as will pages like this:

http://www.ntk.net/grey.html

Meanwhile, the WAI works to make the web back into a document collection
where you can access any document in any way and get content back, without
exception, from wherever, and despite whatever physical barriers have to be
overcome. This is why the WAI lists largely revolve around discussion of
specific ways of marking up documents of different sorts in such a way as to
guarantee that documents are 'viewable' independently of what equipment is
used to do so. We call this 'accessibility', and the goal is to work towards
a web where all documents are fully accessible in this sense.

Anne's posts and those of some others, over the last while, unless I have
seriously misunderstood them, have tended to focus on ways of taking the web
to a place where you can guarantee that all documents are 'understandable'
independently of what (cognitive) equipment is used to do so. That is a
highly laudable goal (to a degree), and, confusingly, is also called
'accessibility'.

However, the two kinds of accessibility are not the same. They operate in
different domains - one operates in the domain of things a users gets, and
one operates in the domain of things a user understands. In consequence, the
ways in which those goals can be reached are not the same. Conflating the
two helps no-one.

There is also a deeper difference. There is no reason why the goal of the
first kind of accessibility should be impossible. I can conceive - in the
abstract - of a system of markup where there was simply no way to produce a
valid document that was inaccessible - and I am sure that this is the
precise direction that the WAI is leading Son-Of-HTML, call it what you
will. (I only wish I could be more specific on the details of this
system...)

However, while it should not and will not stop people working towards it,
there seems to be a clear reason why the goal of universal cognitive
accessiblility is impossible - at least in terms of the web. While one might
be able to produce a document system where, similarly, no-one could produce
a document that someone, somewhere, couldn't understand, this would of
necessity impose semantic restrictions on the scope of ideas and the depth
of discussion that such documents could contain. Web pages impose no such
semantic restrictions.

If you worked out a way of restricting the semantic content of web pages in
order to produce a subset of webpages that everyone could understand,
without exception, there would immediately be another set of webpages - all
the ones that were rejected by your semantic-content restriction schema -
which, by definition, would be inaccessible to people that couldn't
understand them. This is why I say that the goal of making all webpages
cognitively accessible is only highly laudable to a degree, since the only
way to actually enforce it would be to actually censor anything that was too
difficult to convert to a universally understandable language of icons and
non-verbal cues.

You might see that as a counsel of despair written by someone who knows
nothing about cognitive ability issues. You might suggest that there are no
documents anywhere that cannot be rewritten so as to be universally
understandable, but I think I can come up with a counter example, and would
suggest that as soon as there is any document anywhere which someone
somewhere can't understand - because of the content - then your system for a
web where everyone understands everything has to start banning such
documents on the basis of semantic content and content alone. Take Unlambda:

http://www.eleves.ens.fr:8080/home/madore/programs/unlambda/#what_looks

Unlambda is one of a number of programming languages constructed
deliberately to be obfuscated. Unlambda code is deliberately designed to be
almost impossible to read and understand - even by those people who invented
Unlambda.

How would you propose to allow such content in the putative 'web where
everyone can understand everything'? If you change it - replace it with a
system of icons, say - it is no longer Unlambda, and you have lost the
original document in an effectively censorial way. If you just ban it (for
being too hard to process into an iconic format), you are also banning some
things on the basis of semantic content. Either we are back to what is
effectively a subsetting process, where some documents are always going to
be too hard for some people to understand.

Nevertheless, as ever, the real world meets us all somewhere in the middle,
and we do need to find ways to make more or less most documents both more or
less viewable and more or less understandable by more or less everyone.

Since they are so different, however, the accessibility of view (what the
user gets) and the accessibility of cognition (what the user understands)
must be kept seperate from one another. Otherwise we can't achieve either
goal. In practice, it is likely that both kinds of accessibility are only
going to be partially achievable in the short term. Until there is a form of
HTML where accessibility of view is guaranteed, accessibility of cognition
is likely to take second place, since the former does not step into the
dodgy political waters of allowing or disallowing documents on the basis of
semantic content that the latter does; moreover, the former is at least
theoretically possible to universally achieve and the latter is not.

I'll shut up now. Sorry to have ranted on...

Cheers etc.,

Wayne

Wayne Myers
Software Engineer, BBC Digital Media,
Coder/Producer, Betsie Project
http://www.bbc.co.uk/education/betsie/
020-8752-6116

This e-mail, and any attachment, is confidential. If you have received it in error, please delete it from your system, do not use or disclose the information in any way, and notify me immediately. The contents of this message may contain personal views which are not the views of the BBC, unless specifically stated.



