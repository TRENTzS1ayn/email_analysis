docno="lists-077-13341594"
received="Sun Dec 23 07:34:46 2001"
isoreceived="20011223123446"
sent="Sat, 22 Dec 2001 11:40:22 +0000 (GMT)"
isosent="20011222114022"
name="David Woolley"
email="david@djwhome.demon.co.uk"
subject="Re: Multiple versions of a web page"
id="200112221140.fBMBeMp25461@djwhome.demon.co.uk"
charset="us-ascii"
inreplyto="200112201601.fBKG1NvO020072&#64;newbolt.sonic.net"
expires="-1"


To:w3c-wai-ig@w3.org

> Actually, the lowest level can be rather easily implemented.  For example,
> I have a very basic perl script which can extract a universal web page
> from a standard web page which contains the appropriate extractor
> comments.

This approach is a travesty of the whole markup language concept, but,
as it is easiest, is the one that is most likely to get adopted.  The
sites that don't need to save time will simply "save money" by going
this way, rather than doing it better.

If the site has a consistent house style (and if they don't, I would
suggest that the designers are out of control++), and there is enough
understanding of structure for the content providers to actually be
able to indicate the structure, I would suggest that a reasonable
approach would be to write the page as structural HTML, with classes,
and divisions, to impose the higher level structure, then transform
it into the table based page description HTML for the GUI browsers.
This is essentially the server side XML approach, except that the
master version is the fallback version.  One can use additional classes
and/or processing instructions, to hint at the presentational form,
beyond what is implied by obeying the house style.  One could even use
private attributes (optionally stripped to allow validation) to carry
presentational information for the pre-processor.

++ To me, fonts specified all over the place and failing to indicate
headers indicates designers who have no clear view of the style they
want to achieve, but are simply throwing things at the screen.  WYSIWYG
and house styles don't mix all that well.



