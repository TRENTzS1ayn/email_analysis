docno="lists-078-0206600"
received="Thu May 16 10:22:33 2002"
isoreceived="20020516142233"
sent="Thu, 16 May 2002 07:21:11 -0700"
isosent="20020516142111"
name="Thanasis Kinias"
email="tkinias@optimalco.com"
subject="Re: crawling validator"
id="20020516072111.D22015@glaux.ph.cox.net"
charset="iso-8859-1"
inreplyto="3CE1504D.7050008&#64;btinternet.com"
expires="-1"

To: jonathan chetwynd<j.chetwynd@btinternet.com>
Cc:"WAI List (E-mail)"<w3c-wai-ig@w3.org>,www-validator@w3.org


scripsit jonathan chetwynd:
> is there a w3c service that crawls a site and reports errors, in 
> planning perhaps?

WDG's validator [1] has something like this.  If you tell it to validate the
"whole site", it will crawl links which point to files in the same
directory or under, and validate those recursively.

It's not W3C, but it is "real" DTD-based validation.

References

1. Linked from <http://www.htmlhelp.com>

-- 
Thanasis Kinias
Web Developer, Information Technology
Graduate Student, Department of History
Arizona State University
Tempe, Arizona, U.S.A.

Ash nazg durbatul?k, ash nazg gimbatul,
Ash nazg thrakatul?k agh burzum-ishi krimpatul



