docno="lists-078-15735049"
received="Fri Sep 27 20:21:55 2002"
isoreceived="20020928002155"
sent="Fri, 27 Sep 2002 18:21:30 -0400"
isosent="20020927222130"
name="Harvey Bingham"
email="hbingham@acm.org"
subject="Fwd: &quot;A New Way to Read, Not See, Maps&quot;"
id="5.1.0.14.2.20020927180102.00a3c0f0@pop.rcn.com"
charset="us-ascii"
expires="-1"


To:<w3c-wai-ig@w3.org>


Abstract from
ACM TechNews Vol 4, Number 404, September 27, 2002

Wired News (09/25/02); Tosczak, Mark
Software developed by the University of North Carolina at Chapel Hill
offers visually impaired users a way to navigate maps, thus opening up
their participation in geographic research. The Blind Audio Tactile
Mapping System (BATS) is set up so that a sightless user can move a
cursor over a map and determine location and the position of prominent
features by hearing audio cues. For instance, moving the cursor over
land produces the sound of horses galloping, while moving it over water
produces the sound of waves hitting shore. Meanwhile, a speech
synthesizer reads out the name of locations the cursor passes over, and
sometimes spells it out if pronunciation is difficult. Users navigate
with a trackball interface, which proved to be a cheaper and easier
alternative to an early prototype's stylus and touch screen. BATS grew
out of a undergraduate computer science class project organized by
professor Gary Bishop, and Python was selected as the software's
programming language. The students responded so positively to the
challenge that they asked Bishop permission to refine the system over
the summer, and Bishop secured funding from Microsoft to support their
efforts. A new team is incorporating tactile feedback into BATS via
trackballs and mice with force-feedback.
See:
http://www.wired.com/news/technology/0,1282,54916,00.html

Regards/Harvey Bingham



