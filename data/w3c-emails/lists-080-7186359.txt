docno="lists-080-7186359"
received="Wed Dec 10 17:11:11 2003"
isoreceived="20031210221111"
sent="Wed, 10 Dec 2003 22:04:12 +0000 (GMT)"
isosent="20031210220412"
name="David Woolley"
email="david@djwhome.demon.co.uk"
subject="Re: The Cult of Pseudo Accessibility"
id="200312102204.hBAM4CJ20774@djwhome.demon.co.uk"
charset="us-ascii"
inreplyto="3FD77B3A.2000508&#64;acslink.net.au"
expires="-1"


To:w3c-wai-ig@w3.org


> As a programmer you should know that all they have to do is at least in 
> this situation parse the functions calls and match them in a DOM tree 
> table to see if they meet critical or none critical criteria and flag 
> them as such?

You can only do this for stereotyped code (the sort that links (not lynx)
can partially cope with).  I don't think there is any doubt that 
ECMAScript is Turing complete, so the halting problem is unsolvable; that
means that any fully general script analyzer will take an amount  of 
time that can only be determined by actually running the analyzer to fully
analyze the script.  (The halting problem says that you cannot construct
an algorithm that will determine whether an arbitrary program will ever
complete and which, itself, will always complete in finite time.)

More prosaically, function calls can be against objects that are multiply
indirected through object variables; that means that you have to analyze
program and data flow; you cannot do just a static analysis.



