docno="lists-080-9115962"
received="Wed Apr 14 10:11:34 2004"
isoreceived="20040414141134"
sent="Thu, 15 Apr 2004 00:08:17 +1000"
isosent="20040414140817"
name="Charles McCathieNevile"
email="charles@sidar.org"
subject="tools, testers, conformance, etc"
id="2D2BD93D-8E1D-11D8-913D-000A958826AA@sidar.org"
charset="ISO-8859-1"
inreplyto="VA.00000d9f.0460b2c9&#64;tvw.net"
expires="-1"


To:w3c-wai-ig@w3.org


I'm not so sure. Unfortunately I have seen too many results by 
reasonably substantial groups of testers that are as bad as anything an 
ordinary tool puts out, and many very good tests done by people who 
rely on experience because they don't have users to do testing with, 
and don't bother with formal tools.

I suspect it comes down to the people who are running the testing and 
how good at it they are. The better WCAG gets (and more particularly 
the techniques, and testing materials such as those being developed by 
EuroAccessibility, or by Chris Ridpath, and the various tool developers 
who try to make better testing the reason to buy their software), the 
easier it gets to do it right...

cheers

Chaals

On 15 Apr 2004, at 01:00, Julian Voelcker wrote:

> OK, with your average test group you will never be able to test for
> every user scenario, but you will be able to do a far better job than
> just relying on the automated testing tools.
>
--
Charles McCathieNevile                          Fundaci?n Sidar
charles@sidar.org                                http://www.sidar.org



