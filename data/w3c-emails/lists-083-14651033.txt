docno="lists-083-14651033"
received="Mon Jun 12 16:54:07 2000"
isoreceived="20000612205407"
sent="Mon, 12 Jun 2000 16:53:53 -0400 (EDT)"
isosent="20000612205353"
name="Charles McCathieNevile"
email="charles@w3.org"
subject="Re: Proposed minimal requirements for audio/speech checkpoints."
id="Pine.LNX.4.20.0006121652130.14858-100000@tux.w3.org"
charset="US-ASCII"
inreplyto="4.3.1.2.20000612160053.02d79f00&#64;127.0.0.1"
expires="-1"

To:"Gregory J. Rosmaita"<unagi69@concentric.net>
cc: Ian Jacobs<ij@w3.org>, User Agent Guidelines Emailing List<w3c-wai-ua@w3.org>


The way I read Ian's proposal, was taht he was going to propose requirements
for other features of voice such as thosse already included in CSS - it was
just the vague requirement for "other features in general" that was being
removed. 

Charles McCN

On Mon, 12 Jun 2000, Gregory J. Rosmaita wrote:

  aloha, ian!
  
  i agree with your proposal, save for your caveat:
  
  quote
  IMPORTANT: I propose that we delete "and other articulation
  characteristics" from checkpoint 4.11 since that makes it
  much harder to specify minimal requirements.
  unquote
  
  it wouldn't be much harder to specify minimal requirements for "other 
  articulation characteristics" if you simply applied the same implementation 
  example to that phrase that you used for volume -- the aural media rules of 
  CSS2...  the minimal requirements for "other articulation characteristics" 
  should be those listed as "speech characteristics" [1] in chapter 19 of the 
  CSS2 recommendation that aren't already highlighted by separate UAAG 
  checkpoints -- namely:
  
           voice-family;
           stress;
           and richness
  
  the minimal requirements should also list equivalents for CSS2's 
  "speak-properties" [2]:
  
           speak-punctuation and speak-number
  
  and for CSS2's "speaking-properties"  [3]
  
           normal, none, and spell-out
  
  as well as the "pause" properties [4]
  
           pause-before and pause-after
  
  all of which are elemental aspects of a speech synthesis engine...  cueing 
  is pretty damn important, as well, but i think that i'd settle for the 
  above as "minimal", although i'd prefer a self-voicing UA to also implement 
  some sort of cue-before and cue-after configuration option, as well as a 
  play-during configuration and control
  
           gregory.
  
  References
  [1] http://www.w3.org/TR/CSS2/aural.html#voice-char-props
  [2] http://www.w3.org/TR/CSS2/aural.html#speech-props
  [3] http://www.w3.org/TR/CSS2/aural.html#speaking-props
  [4] http://www.w3.org/TR/CSS2/aural.html#pause-props
  

--
Charles McCathieNevile    mailto:charles@w3.org    phone: +61 (0) 409 134 136
W3C Web Accessibility Initiative                      http://www.w3.org/WAI
Location: I-cubed, 110 Victoria Street, Carlton VIC 3053
Postal: GPO Box 2476V, Melbourne 3001,  Australia 



