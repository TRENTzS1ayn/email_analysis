docno="lists-083-14866431"
received="Tue Jun 13 14:44:19 2000"
isoreceived="20000613184419"
sent="Tue, 13 Jun 2000 14:44:11 -0400"
isosent="20000613184411"
name="Ian Jacobs"
email="ij@w3.org"
subject="Re: Proposal to delete checkpoint 3.2 and expand 4.10"
id="394680FB.8A9A9376@w3.org"
charset="us-ascii"
inreplyto="4.3.1.2.20000613125505.00bec1c0&#64;staff.uiuc.edu"
expires="-1"


To: Jon Gunderson<jongund@uiuc.edu>
CC:w3c-wai-ua@w3.org

Jon Gunderson wrote:
> 
> Do you have any reference implementation of this?

No, I'm hoping developers will answer here.
 
> It seems like every page would require creating a dynamic set of volume
> controls that reflect all of the audio resources referenced in the
> document.

Yes.

> This seems to me to an un managable tasks for most users,
> identify and setting volumes for resources rather than devices.

So if you want to keep the document at the current level (synth
speech v. the rest of audio), that's ok. But is it easier for
developers to distinguish synth from other sources or treat
everything the same? And is synth a special case that merits
a requirement while other types of audio do not?

 -Ian

> At 09:26 AM 6/13/00 -0400, you wrote:
> >Jon Gunderson wrote:
> > >
> > > Ian,
> > > So every time a sound object is rendered to the user will be prompted for
> > > volume for that resource?
> >
> >You're not prompted. You can go in and set the volume if you wish.
> >It's not a requirement on the user to set the volume, but a requirement
> >on the user agent to change volume if they wish.
> >
> > > If is a SMIL document with 50 sounds sources they will need to specify 50
> > > volume levels?
> >
> >Not required to set, but given the option of setting any one,
> >should they need to.
> >
> >  - Ian
> > >
> > > At 10:43 AM 6/12/00 -0400, Ian Jacobs wrote:
> > > >Jon Gunderson wrote:
> > > > >
> > > > > Ian,
> > > > >
> > > > > How do you define an audio source?
> > > > > Is a source an author specification of some type of audio
> > > > > resource or is it an API or hardware used to play the
> > > > > author specified audio resource?
> > > >
> > > >Content provided by the author that when rendered,
> > > >produces sound. This could be pre-recorded sounds
> > > >or synthesized speech, for example.
> > > >
> > > >   - Ian
> > > >
> > > >
> > > > > At 10:28 PM 6/9/00 -0400, Ian Jacobs wrote:
> > > > > >Hello,
> > > > > >
> > > > > >After several hours of discussions today with Charles
> > > > > >and Eric Hansen, I would like to propose the following
> > > > > >changes to the document. The checkpoint numbers are those
> > > > > >of the 7 May Guidelines [1].
> > > > > >
> > > > > >This proposal concerns "volume" related checkpoints. Here
> > > > > >are the checkpoints that include requirements for volume
> > > > > >control:
> > > > > >
> > > > > >3.2 Allow the user to turn on and off rendering of
> > > > > >     background audio. [Priority 1]
> > > > > >3.4 Allow the user to turn on and off rendering of
> > > > > >     audio. [Priority 1]
> > > > > >4.8 Allow the user to configure the audio volume.
> > > > > >     [Priority 2]
> > > > > >4.10 Allow the user to configure synthesized speech volume.
> > > > > >     [Priority 1]
> > > > > >
> > > > > >At the 8 June teleconference, we resolved to change
> > > > > >the priority of 4.8 to P1.
> > > > > >
> > > > > >I propose changing the requirements embodied by
> > > > > >these three checkpoints to the following:
> > > > > >
> > > > > >  1) On/off control of global audio
> > > > > >     (When audio is a distraction. This is a special
> > > > > >      case of the second requirement, but can stand alone.)
> > > > > >
> > > > > >  2) Control of global audio volume
> > > > > >     (For users who are hard of hearing and users for whom
> > > > > >      audio is a distraction.)
> > > > > >
> > > > > >  3) Relative control of volume among audio objects.
> > > > > >     (Currently, this is only applied to the particular
> > > > > >      case of synthesized speech. For notes on discussion
> > > > > >      about this requirement, refer to 8 June minutes [2].)
> > > > > >
> > > > > >Note that checkpoint 3.2 is about "background audio". What is the
> > > > > >difference between turning off background audio and turning
> > > > > >off audio, except when background audio is an identifiable track
> > > > > >that may be turned off independently of other audio? I'm not
> > > > > >sure there is a difference, but to capture the requirement
> > > > > >of being able to make background audio go away, I propose
> > > > > >augmenting the scope of 4.10 to cover all audio objects.
> > > > > >Thus, we would end up with the following three priority
> > > > > >one checkpoints:
> > > > > >
> > > > > >1) Allow the user to turn on and off rendering of audio.
> > > > > >2) Allow the user to configure the audio volume.
> > > > > >3) Allow the user to control the volume of audio sources
> > > > > >    independently.
> > > > > >
> > > > > >Notes:
> > > > > >
> > > > > >1) The applicability clause is in effect here. Therefore,
> > > > > >    if some other agent renders the audio, that agent is
> > > > > >    responsible for volume control.
> > > > > >
> > > > > >2) It might be possible to narrow the scope of checkpoint
> > > > > >    three to the two cases already discussed in the document:
> > > > > >    background audio and synthesized speech. However, defining
> > > > > >    "background audio" is difficult and I don't know whether
> > > > > >    life would be any easier on developers if we did. Does anyone
> > > > > >    know of existing software where the user can control the
> > > > > >    volume of different audio sources independently?
> > > > > >
> > > > > >  - Ian
> > > > > >
> > > > > >[1] http://www.w3.org/WAI/UA/WD-UAAG10-20000507
> > > > > >[2]
> > http://lists.w3.org/Archives/Public/w3c-wai-ua/2000AprJun/0429.html


-- 
Ian Jacobs (jacobs@w3.org)   http://www.w3.org/People/Jacobs
Tel:                         +1 831 457-2842
Cell:                        +1 917 450-8783



