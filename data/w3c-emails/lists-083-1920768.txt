docno="lists-083-1920768"
received="Fri Sep  3 13:54:02 1999"
isoreceived="19990903175402"
sent="Fri, 03 Sep 1999 14:01:08 -0400"
isosent="19990903180108"
name="Al Gilman"
email="asgilman@iamdigex.net"
subject="RE: test suites"
id="199909031803.OAA24250@smtp1.mail.iamworld.net"
charset="us-ascii"
inreplyto="C35556591D34D111BB5600805F1961B90C311A0B&#64;RED-MSG-47"
expires="-1"


To: Chris Wilson<cwilso@microsoft.com>, WAI UA group<w3c-wai-ua@w3.org>
Cc: Rob Relyea<rrelyea@microsoft.com>

At 08:50 AM 9/2/99 -0700, Chris Wilson wrote:
>I'd be interested in hearing suggestions about how a UA might provide
>mouse-over activation without a mouse.  We haven't thought up any good
>solutions.

AG:

Caveat: I haven't read others' responses to this, yet.

Before I get into specific solutions scenarios, I want to review a few
things I think me may know about a solution if there is one.

There is a concept of severity or weight of consequences that us useful in
understanding how different events are used.  The main idea I have at the
moment is that OnMouseOver is a light touch, OnHover is a slightly heavier
touch, OnClick is a heavier touch yet and OnDoubleClick is the heaviest
touch of all these.

What we really want is the ability to classify the actual consequences of
running the even-handler script, and extract severity grading appropriate
to the class of change and the current operational profile of user
interface couplings.

But lacking adequate visibility into the transaction associated with a
given event, we can guess based on the conventional severity grading of the
events used to trigger changes.  So mapping OnScreenEvent events to some
other form of screen-free activation method is something of a hack and a
guessing game, but it is still worth doing.

The basic or universal method is the context menu.  This is familiar as the
right mouse button in Microsoft Windows.  There is also a dedicated Context
Menu key in the Windows 95 keyboard.

In the absense of a viable screen medium of exchange with graphic display
and continuously varying pointing, one wants to create an interaction world
of abstract, named objects.  Anything that has an event handler defined for
it is an object with methods.  Anything that has text content has a speak
method in the presence of TTS capability (which is regarded as readily
available and is a system capability all services delivering information in
text form should be prepared to interoperate with).  The key to the most
generic method of accessing screen-oriented event handlers is the ability
to make any object bearing such a method capable of being the current
context in the sense of what is exposed by the current context menu.  The
all event handlers should be action opportunities exposed through this menu.


In addition, there are quite likely other modes of triggering that are
useful in specific scenarios.  One is the machine to teach reading.  In
that case there is a reading cursor which is moving through the speakable
content.  It is quite likely that the OnMouseOver response should be
stimulated when the reading process arrives at the leading edge of the
reading stream for an entity with an OnMouseOver response defined.  This
may need to be configurable in terms of whether the OnMouseOver response is
simply executed in its native terms, or whether any textual content in a
transient display is fed to the speaking process as well, and if spoken is
it spoken first or last, or does the reading pause at the end of the prime
content for the user to elect to read the annotation or press on.

That's my buffer contents on how to operate with behaviors that the author
conceived of as OnMouseOver responses but in user interface contexts where
the screen metaphor is not something that is maintainable as a shared
two-dimensional graphic frame of reference shared by application and user.

Al


>
>-Chris Wilson
> Internet Explorer Team
>
>-----Original Message-----
>From: Charles McCathieNevile [mailto:charles@w3.org]
>Sent: Thursday, September 02, 1999 8:44 AM
>To: WAI UA group
>Subject: test suites
>
>
>One of the things that the CSS working group has produced is test suites - a
>set of pages you can use to check whether you conform.
>
>In reading through the evaluation tests I noticed that there are certain
>clear things that should be checked. A classic example is keyboard
>activation
>- how does a user activate an onMouseover without a mouse?
>
>perhaps we should create some example pages for testing.
>
>This also relates to WCAG - what should we test for in areas where WCAG has
>an "until user agents" requirement? SHould we test pages which conform to
>WCAG, or pages which do not, or both?
>
>Hmm. I feel like I have asked a lot of questions in the last week or so, and
>have not offered much in the way of answers or even suggested answers.
>
>Charles McCN 
>
>--Charles McCathieNevile            mailto:charles@w3.org
>phone: +1 617 258 0992   http://www.w3.org/People/Charles
>W3C Web Accessibility Initiative    http://www.w3.org/WAI
>MIT/LCS  -  545 Technology sq., Cambridge MA, 02139,  USA
> 



