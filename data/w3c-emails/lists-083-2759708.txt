docno="lists-083-2759708"
received="Wed Sep 22 16:47:29 1999"
isoreceived="19990922204729"
sent="Wed, 22 Sep 1999 15:52:11 -0700"
isosent="19990922225211"
name="Jon Gunderson"
email="jongund@staff.uiuc.edu"
subject="RE: Guideline 2 &amp; device independence"
id="4.1.19990922155040.00cf36a0@staff.uiuc.edu"
charset="us-ascii"
inreplyto="OCEDIDJABCKNMLGMBFLGGEMDCBAA.danson&#64;miseri.edu"
expires="-1"


To:<w3c-wai-ua@w3.org>

Part of the conformance to our guidelines would require the use of standard
interfaces, so all should be good if a user agent wants to comply with the
guidelines. 
Jon


At 02:48 PM 9/22/99 -0400, Denis Anson wrote:
>Actually, there are those in the world who could use the "keyboard" language
>to make things inaccessible.  What we really want is access via character
>codes, such as the Control-X code.  So long as the UA uses standard system
>hooks to get character codes from the keyboard, all is good.  But if the
>author decides to read the keyboard hardware directly, alternative access
>technologies would be cut out.  The question is how to phrase the desire for
>direct shortcuts via character codes or keyboard events (the Alt key doesn't
>have a character code, I don't think, but might be used to control some
>types of system events, such as activating the menu bar.) in language that
>is unambiguous.
>
>Denis Anson, MS, OTR
>Assistant Professor
>College Misericordia
>301 Lake St.
>Dallas, PA 18612
>
>Member since 1989:
>RESNA: An International Association of Assistive Techology Professionals
>Website: http://www.resna.org
>RESNA ANNUAL CONFERENCE -- "RESNA 2000"
>ORLANDO, FL, JUNE 28 -- July 2, 2000
>
>-----Original Message-----
>From: w3c-wai-ua-request@w3.org [mailto:w3c-wai-ua-request@w3.org]On Behalf
>Of mark novak
>Sent: Wednesday, September 22, 1999 12:43 PM
>To: Marja-Riitta Koivunen; w3c-wai-ua@w3.org
>Subject: Re: Guideline 2 & device independence
>
>MN:  in theory I agree with alot of what you're saying Marja-Riitta.  One
>of the things in favor of access, as defined in terms of keyboard access,
>is that
>voice, Morse, scanning, switch, etc., input methods all get translated into
>keyboard events inside the operating system, thus by "default" if an object
>is accessible via the keyboard, it should be accessible via these other
>methods.
>
>No guarentees for the future, but any such change would break alot of
>software.
>
>
>
>At 10:47 AM 9/22/99, Marja-Riitta Koivunen wrote:
>>Sorry, but I still think guideline 2 is too device specific when it talks
>>about keyboard access.
>>
>>To understand it better I first explain how I think the system works and
>>then what I think we try to say in higher level.
>>
>>An input device has any number of buttons, maybe location info, microphone
>>etc. The computer has a device driver that converts the pushing of buttons,
>>saying a word, using morse code etc. to set of events that the user agent
>>can understand. When UA gets the events it can activate functions.
>>
>>Some of the events activate a user level function directly. These are
>>shortcuts to the functions and often the event names are related to
>>keyboard e.g. "control X".
>>
>>Often in graphical UI events consist of button pushes and pointer
>>movements. The location info of a pointing device is used to decide which
>>graphical object should handle the events and activate the functions and
>>again the object may use the location info inside to decide which function
>>is activated.
>>
>>So I guess what we want here is to be able to activate functions also
>>directly without a need of the pointing information which may be hard to
>>create in the device driver with certain non pointing devices. In other
>>words we want direct shortcuts to the functionality so that non-pointing
>>devices can easily provide that. The fact that the names in the event level
>>often come from a keyboard world does not mean we only want keyboard. For
>>instance, the "control X" event could be created by the device driver of
>>speech device when user says "delete" or creates morse code sequence "-..".
>>
>>So could we state the GL 2 something like "Provide direct shortcuts to the
>>functionality of the user interface (that can be activated by non-pointing
>>devices)"?
>>
>>Then the checkpoints probably need to be rephrased a little but keyboard
>>can be used as example.
>>
>>What do you think?
>>
>>Marja
>

Jon Gunderson, Ph.D., ATP
Coordinator of Assistive Communication and Information Technology
Chair, W3C WAI User Agent Working Group
Division of Rehabilitation - Education Services
University of Illinois at Urbana/Champaign
1207 S. Oak Street
Champaign, IL 61820

Voice: 217-244-5870
Fax: 217-333-0248
E-mail: jongund@uiuc.edu
WWW:http://www.staff.uiuc.edu/~jongund
http://www.w3.org/wai/ua
http://www.als.uiuc.edu/InfoTechAccess



