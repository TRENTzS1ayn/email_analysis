docno="lists-083-2863700"
received="Thu Sep 23 16:42:10 1999"
isoreceived="19990923204210"
sent="Thu, 23 Sep 1999 16:42:08 -0400 (EDT)"
isosent="19990923204208"
name="Charles McCathieNevile"
email="charles@w3.org"
subject="Re: Guideline 2 &amp; device independence"
id="Pine.LNX.4.10.9909231430370.1883-100000@tux.w3.org"
charset="US-ASCII"
inreplyto="4.1.19990922164642.03aac350&#64;127.0.0.1"
expires="-1"

To: Marja-Riitta Koivunen<marja@w3.org>
cc: Jon Gunderson<jongund@staff.uiuc.edu>,w3c-wai-ua@w3.org


I think there is still an issue here - although the single most useful thing
that can be done is for all keyboard interfaces to become omnipotent, and for
that reason may merit being the first checkpoint, worded something like

 "For user agents which have a keyboard interface ensure that all functions
  of the user agent can be accessed through menass of the keyboard only,
  using system standards"

rationale is that most (but not all) assistive input technologies rely on
mimicking the keyboard. 

techniques:
Ensure that all menu options and dialog functions can be accessed from the
keyboard (this is a fairly  window-centric technique).
Ensure that document interaction (selection, focus changes, firing of events)
can be done by the keyboard (see my email on how to do some of this)
Follow system standards in designing interfaces (see also checkpoint 6.x


This may be important enough to separate it from a more general requirement
that input from any single supported device be sufficient to operate the
tool. 

Charles McCN



