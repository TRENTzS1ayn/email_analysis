docno="lists-083-2912589"
received="Fri Sep 24 10:19:50 1999"
isoreceived="19990924141950"
sent="24 Sep 1999 10:20:58 +0000"
isosent="19990924102058"
name="Madeleine Rothberg"
email="Madeleine_Rothberg@wgbh.org"
subject="Re: MINUTES(edited): W3C WAI User Agent Telecon 22 September 1999"
id="n1273953869.72068@wgbh.org"
charset="ISO-8859-1"
inreplyto="MINUTES(edited): W3C WAI User Agent Telecon 22 September 1999"
expires="-1"


To:"Ian Jacobs"<ij@w3.org>
Cc:w3c-wai-ua@w3.org

         Reply to:   RE>>MINUTES(edited): W3C WAI User Agent Telecon 22 September*

I was thinking of an output analogy to the input example of users
who don't have pointing devices, as used in the first paragraph
of the Guideline 1 rationale:

"Since not all users make use of the same hardware for input or 
output, software must be designed to work with the widest possible 
range of devices. For instance, not all users have pointing devices, 
so software must not rely on them for operation. Users must be able 
to reach all functionalities offered by the user agent interface with 
all input devices supported by the underlying system. "

The concern is not content-related audio and text but user agent
alerts or messages. An example might be AOL's audio "You've Got Mail."
If that was the only way to know that you had new email, and you
couldn't hear or didn't have speakers on your browsing device, you
wouldn't know you had mail. (Luckily AOL also has some visual change
if you have mail.) For inclusion in the Guideline text, I propose
something like:

"And not all users have speakers, or the ability to hear, so software
must not rely on audio output for messages and alerts. Any output provided
in audio should also be available in other output media. Text is the most
general output media, since most alternative output mechanisms rely on the
presence of system-drawn text on the screen."

If this is too much detail for this part of the document, feel free to
trim it and perhaps use the rest in the techniques.

-Madeleine

--------------------------------------
Date: 9/23/99 5:57 PM
To: Madeleine Rothberg
From: Ian Jacobs
Jon Gunderson wrote:
> 
> 5) Issue #80 Make audio available as text.
> 
> http://cmos-eng.rehab.uiuc.edu/ua-issues/issues-linear.html#80
> 
> MR: In rationale of Guideline 1, I thought an additional example on output
> device independence. Example would meet needs of deaf users and output device
> independence. Take text from [3]:
> 
> "And any output provided in audio should also be available in text since
> most alternative output mechanisms rely on the presence of system-drawn
> text on the
> screen."

>AG: Also add cross-reference to show sounds in techniques document. 

>Resolved: ok to add text to introduction 

Hi,

I looked back at this text from [3] and I'm not sure I understand.
Why does it belong in the section on device independence? Is this
about user agents *generating* text from audio? Or about ensuring
that author-supplied text is available? 

Or does "audio" mean "speech"?

Before adding to the document, I need some clarification.

Thank you,

 - Ian

[3] http://lists.w3.org/Archives/Public/w3c-wai-ua/1999JulSep/0083.html



