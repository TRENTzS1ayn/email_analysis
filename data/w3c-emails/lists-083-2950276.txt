docno="lists-083-2950276"
received="Fri Sep 24 12:12:11 1999"
isoreceived="19990924161211"
sent="Sun, 24 Oct 1999 11:16:35 -0700"
isosent="19991024181635"
name="Jon Gunderson"
email="jongund@staff.uiuc.edu"
subject="Re: MINUTES(edited): W3C WAI User Agent Telecon 22 September   1999"
id="4.1.19991024111609.00cfe450@staff.uiuc.edu"
charset="us-ascii"
inreplyto="n1273953869.72068&#64;wgbh.org"
expires="-1"


To:"Madeleine Rothberg"<Madeleine_Rothberg@wgbh.org>,"Ian Jacobs"<ij@w3.org>
Cc:w3c-wai-ua@w3.org

Thanks Madeleine for making this clear.
Jon


At 10:20 AM 9/24/99 +0000, Madeleine Rothberg wrote:
>         Reply to:   RE>>MINUTES(edited): W3C WAI User Agent Telecon 22 
>September*
>
>I was thinking of an output analogy to the input example of users
>who don't have pointing devices, as used in the first paragraph
>of the Guideline 1 rationale:
>
>"Since not all users make use of the same hardware for input or 
>output, software must be designed to work with the widest possible 
>range of devices. For instance, not all users have pointing devices, 
>so software must not rely on them for operation. Users must be able 
>to reach all functionalities offered by the user agent interface with 
>all input devices supported by the underlying system. "
>
>The concern is not content-related audio and text but user agent
>alerts or messages. An example might be AOL's audio "You've Got Mail."
>If that was the only way to know that you had new email, and you
>couldn't hear or didn't have speakers on your browsing device, you
>wouldn't know you had mail. (Luckily AOL also has some visual change
>if you have mail.) For inclusion in the Guideline text, I propose
>something like:
>
>"And not all users have speakers, or the ability to hear, so software
>must not rely on audio output for messages and alerts. Any output provided
>in audio should also be available in other output media. Text is the most
>general output media, since most alternative output mechanisms rely on the
>presence of system-drawn text on the screen."
>
>If this is too much detail for this part of the document, feel free to
>trim it and perhaps use the rest in the techniques.
>
>-Madeleine
>
>--------------------------------------
>Date: 9/23/99 5:57 PM
>To: Madeleine Rothberg
>From: Ian Jacobs
>Jon Gunderson wrote:
>> 
>> 5) Issue #80 Make audio available as text.
>> 
>> http://cmos-eng.rehab.uiuc.edu/ua-issues/issues-linear.html#80
>> 
>> MR: In rationale of Guideline 1, I thought an additional example on output
>> device independence. Example would meet needs of deaf users and output
device
>> independence. Take text from [3]:
>> 
>> "And any output provided in audio should also be available in text since
>> most alternative output mechanisms rely on the presence of system-drawn
>> text on the
>> screen."
>
>>AG: Also add cross-reference to show sounds in techniques document. 
>
>>Resolved: ok to add text to introduction 
>
>Hi,
>
>I looked back at this text from [3] and I'm not sure I understand.
>Why does it belong in the section on device independence? Is this
>about user agents *generating* text from audio? Or about ensuring
>that author-supplied text is available? 
>
>Or does "audio" mean "speech"?
>
>Before adding to the document, I need some clarification.
>
>Thank you,
>
> - Ian
>
>[3] http://lists.w3.org/Archives/Public/w3c-wai-ua/1999JulSep/0083.html

Jon Gunderson, Ph.D., ATP
Coordinator of Assistive Communication and Information Technology
Chair, W3C WAI User Agent Working Group
Division of Rehabilitation - Education Services
University of Illinois at Urbana/Champaign
1207 S. Oak Street
Champaign, IL 61820

Voice: 217-244-5870
Fax: 217-333-0248
E-mail: jongund@uiuc.edu
WWW:http://www.staff.uiuc.edu/~jongund
http://www.w3.org/wai/ua
http://www.als.uiuc.edu/InfoTechAccess



