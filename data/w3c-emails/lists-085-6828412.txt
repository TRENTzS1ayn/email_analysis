docno="lists-085-6828412"
received="Fri Feb 23 13:19:04 2001"
isoreceived="20010223181904"
sent="Fri, 23 Feb 2001 13:16:19 -0500"
isosent="20010223181619"
name="Denis Anson"
email="danson@miseri.edu"
subject="RE: [Action] Issue 443: Repair of device-dependent   author-specified   behavior."
id="000001c09dc4$b8f1f770$17dcc241@deniscomputer"
charset="us-ascii"
inreplyto="4.3.1.2.20010221185056.0322eda0&#64;staff.uiuc.edu"
expires="-1"

To:"'Jon Gunderson'"<jongund@uiuc.edu>,"'Ian Jacobs'"<ij@w3.org>,<w3c-wai-ua@w3.org>


Ian and Jon,

If I understand this correctly, checkpoint A would apply to chrome,
checkpoint B would apply to content that can be accessed in a
device-independent manner, and C applies to those things that are device
dependent.  This would imply, I think, that the only things that the
user agent must do is provide sufficient functionality to provide mouse,
keyboard, and voice control of those things that are device independent,
but would make priority 3 support for any code that is not specifically
written as device independent.  It would not require an effort, on the
part of the agent, to emulate the mouse via the keyboard or voice, or
any other such interface.

This seems to me to be leaving too much to the author.  When Joe
Highschool designs a page, he has a relatively simple concept of how a
person would interact with the page.  He thinks that you would use the
mouse to scratch the silver paint off of the lotto ticket.  Since he has
never thought about disability issues, why would he think about device
independent controls?  Under this scenario, there is no need for the
user agent to emulate the mouse via other input methods, and the page is
inaccessible. 

As it happens, there are examples of interface emulation in existence
between these three modalities.  You can use MouseKeys to move the mouse
via the keyboard.  You can use an on-screen keyboard to type with a
mouse.  And you can use voice input to generate character streams and to
move the mouse.  None of these is perfect emulation, but they do allow
placing a mouse in a location, clicking, double-clicking, or generating
characters without any use of the "native" device.  I could,
theoretically, use the keyboard to move the mouse back and forth over
the lotto ticket to scratch off the silver paint.  (Although if I were
blind, I wouldn't know where to move the mouse.  But accessibility
includes other disabilties than vision.)

I'm afraid that this new wording would allow an agent to ignore
interface emulation support, which would not provide access to the
content of many pages.

Denis

-----Original Message-----
From: w3c-wai-ua-request@w3.org [mailto:w3c-wai-ua-request@w3.org] On
Behalf Of Jon Gunderson
Sent: Wednesday, February 21, 2001 7:52 PM
To: Ian Jacobs; w3c-wai-ua@w3.org
Subject: Re: [Action] Issue 443: Repair of device-dependent
author-specified behavior.


Ian,
I like the reasoning behind the proposal.  I agree that the repair we
have 
talked about has dubious guarantees of making content accessible.  What
do 
other people think of the proposal?

Jon


At 01:40 PM 2/21/2001 -0500, Ian Jacobs wrote:
>Hello,
>
>Per my action item assigned at the 15 February 2001 teleconference [1] 
>about issue 443 [2], please consider this proposal for which 
>device-dependent repair requirements should appear in UAAG 1.0.
>
>Checkpoint 1.1 of the 26 January 2001 Guidelines [3] states:
>
>    "Ensure that the user can operate the user agent fully through
>    keyboard input alone, pointing device input alone, and voice
>    input alone. [Priority 1]"
>
>I propose splitting this checkpoint in three (rough wording
>here):
>
>   Checkpoint A: "Ensure that the user can operate the user agent's
>   native functionalities through keyboard input alone, pointing
>   device input alone, and voice input alone. [Priority 1]"
>
>   Checkpoint B: "Ensure that the user can operate
>   device-independent functionalities specified in content through
>   keyboard input alone, pointing device input alone, and voice
>   input alone. [Priority 1]"
>
>   Checkpoint C: "Allow configuration so that the user can operate
>   device-dependent functionalities specified in content through
>   other devices (e.g., simulate pointing device specific behavior
>   through the keyboard). In this configuration, alert the user when
>   an active element has device-specific behaviors associated.
>   [Priority 3]"
>
>I think that checkpoint C should be Priority 3 because it is likely to 
>provide incomplete repair. Thus, it clearly does not qualify for P1 by 
>definition:
>
>    "This checkpoint must be satisfied by user agents, otherwise
>    one or more groups of users with disabilities will find it
>    impossible to access the Web."
>
>There is no guarantee that if satisfied, checkpoint C will make access 
>possible. [I would also note that our priority statements don't say 
>anything about the responsibilities of other parties. This is clearly 
>an authoring issue first.]
>
>Consider these scenarios:
>
>1) The author has created content that is device independent. In this 
>case, checkpoint B applies.
>
>2) The author has created content that is device-dependent, but has 
>also provided alternative content (per WCAG 1.0 checkpoints 9.2 and 
>11.4). In this case, emulation is not required since the author has 
>ensured access.
>
>3) The author has created content that is device-dependent, and has not

>provided an alternative. The device-dependent content is
>either:
>
>   a) Content that doesn't really depend on a particular device
>      but has just been encoded that way, or
>
>   b) Content that really does depend on a particular device
>      (e.g., a user interface where the user scratches the
>      "silver paint" on an electronic lottery ticket to
>       reveal a hidden number).
>
>The user agent can't recognize the difference in general, since 
>handlers are built with scripts. So that means that, in general, the 
>user agent is not likely to repair any better content of type
>(3a) over content of type (3b).
>
>Repair in case (3a) is probably useful to some users, can be carried 
>out automatically, and is technically feasible (e.g., the UA could 
>throw an "onmouseover" event whenever an "onfocus" event occurs, or 
>implement a "zap-mouse-to-focus" functionality).
>
>However, in case (3b), emulation is not likely to help some users.  
>Even a tool such as MouseKeys will not help some users (e.g., users who

>are blind) interact with the user interface. If the author has designed

>content that expressly takes advantage of the nature of two-dimensional

>visual space, there's not much users who are blind can do with 
>certainty. Worse, emulating mouse events might cause unexpected 
>behavior to occur, thus disorienting the user.  And, emulation of 
>certain pointing device events is less obvious (e.g., how do you 
>translate "onmousemove" to the keyboard?), so repair by the UA would 
>likely be incomplete on this axis as well.
>
>In our current definition of "active element", we don't expect the user

>agent to recognize (and thus repair) the class of author-specified 
>behaviors that are encoded through "event bubbling" techniques.
>
>Finally, the user agent should not be required to emulate 
>mouse-specific behaviors that are not controlled by the user agent 
>(e.g., the case of server-side image maps).
>
>----------
>CONCLUSION
>----------
>
>- Emulation of author-supplied device-specific behaviors seems to be 
>useful for some cases, and not helpful (or even disorienting) in 
>others.
>
>- The user agent is not expected to recognize the useful cases from the

>non-useful cases since behaviors are encoded through scripts today. 
>This means that the user agent couldn't "warn" the user, for example.
>
>- Repair functionalities are likely to be incomplete and not guarantee 
>access, so I think that they should be Priority 3.
>
>  - Ian
>
>----------
>References
>----------
>
>[1] http://lists.w3.org/Archives/Public/w3c-wai-ua/2001JanMar/0227.html
>[2] http://server.rehab.uiuc.edu/ua-issues/issues-linear-lc2.html#443
>[3] http://www.w3.org/WAI/UA/WD-UAAG10-20010126/
>
>--
>Ian Jacobs (jacobs@w3.org)   http://www.w3.org/People/Jacobs
>Tel:                         +1 831 457-2842
>Cell:                        +1 917 450-8783

Jon Gunderson, Ph.D., ATP
Coordinator of Assistive Communication and Information Technology
Division of Rehabilitation - Education Services MC-574 College of
Applied Life Studies University of Illinois at Urbana/Champaign 1207 S.
Oak Street, Champaign, IL  61820

Voice: (217) 244-5870
Fax: (217) 333-0248

E-mail: jongund@uiuc.edu

WWW: http://www.staff.uiuc.edu/~jongund
WWW: http://www.w3.org/wai/ua



