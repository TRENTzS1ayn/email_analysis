docno="lists-095-2358406"
received="Thu Jan  4 05:52:28 2001"
isoreceived="20010104105228"
sent="Thu, 4 Jan 2001 05:50:27 -0500 (EST)"
isosent="20010104105027"
name="Charles McCathieNevile"
email="charles@w3.org"
subject="RE: Accessibility of web pages"
id="Pine.LNX.4.30.0101040548460.29358-100000@tux.w3.org"
charset="US-ASCII"
inreplyto="Pine.GSO.4.21.0101041025220.7213-100000&#64;neelix"
expires="-1"

To: Hugh Sasse Staff Elec Eng<hgs@dmu.ac.uk>
cc: Dave  J Woolley<david.woolley@bts.co.uk>,"'www-amaya@w3.org'"<www-amaya@w3.org>


On Thu, 4 Jan 2001, Hugh Sasse Staff Elec Eng wrote:

  On Thu, 4 Jan 2001, Charles McCathieNevile wrote:

  > authors to fix things that need fixing. (As well as having a way of recording
  > information if a Human tested something difficult to test by machine, that
  > persists when a new tool is used to work on the content.)

  ...This last bit I'm not sure about.  If new work is done on the content,
  then you have to re-test accessibility again in case it has been broken.
  Or is this for regression testing, so that the site changes can be
  compared to previous tests?


The idea is that a tool knows what has been done to a page, so it knows what
bits are worth re-testing and what aren't. (part of such a system would be
having a way of checking to see what had been hand-edited in the meantime,
and does need retesting when a smarter tool picks it up).

Charles



