docno="lists-101-0253476"
received="Thu Jun 28 12:08:31 2001"
isoreceived="20010628160831"
sent="Thu, 28 Jun 2001 10:04:18 -0600"
isosent="20010628160418"
name="Arnold, Curt"
email="Curt.Arnold@hyprotech.com"
subject="RE: [General] domconftest now a project at SourceForge"
id="70E215722F6AD511820A000103D141D40AA3F8@thor.aeathtl.com"
charset="iso-8859-1"
inreplyto="[General] domconftest now a project at SourceForge"
expires="-1"


To:"'www-dom-ts@w3.org'"<www-dom-ts@w3.org>

I guess we should spend some time on what the CVS should look like since
it is impossible to undo changes without leaving a trace.

We could put all submissions into a submissions module with subprojects
for the contributors

submissions
   submissions/nist
      submissions/nist/dom1
   submissions/microsoft
   submissions/carnold
   ..

The files in this module would be a verbatim copy of what was submitted
and would not be modified.

For the active project:

domconftest
     tests
     java
         org
            w3c
                dom
                    testing
     ecmascript
     adapters
        junit
     

The structure below tests would mimic the organization used by NIST in
their submission below the tests project.  For example,
domconftest/test/dom1/fundamental/attribute/attributeName.xml, etc.

domconftest/java/org/w3c/dom/testing would only contain the interface
and abstract class definitions.  Actual tests would be in the same
namespace but generated in the build/java/org/w3c/dom/testing.

domconftest would contain an ANT build file and the transforms.

domconftest/adapters could contain source for adapters, code that allows
domconftest.jar to run in a specific test harness like JUnit.

Probably need to get an official decision about w3c package names we can
use.  I've been temporarily using org.w3c.dom.testing.

Mary Brady wrote:
>Sure, I'll help -- I should have the rest of 
>the fundamental and extended tests ready 
>by tomorrow.  

If the described structure seems appropriate, then
it would be beneficial if you could import your tests
into the submissions/nist and domconftest/tests directories.

>After the core tests work, 
>we'll have to add metadata info -- but I 
>think I can write a transform to put our 
>original work into the rdf framework -- 
>is this what we want to do?  

Not quite sure what you are starting from.  I thought
the test matrix was almost a manual affair.

>How do we  envision the metadata info being used?  Can 
>we write a transform that will allow it to 
>be displayed in a web browser, or will we 
>have to transform off-line and make a html 
>version available? 

Since building a test matrix would require crawling all the
available tests, I think generating it is part of the build
process.  You could capture the entire matrix in RDF by
appending descriptions of the tests to the subjects.rdf file
and using a browser side transform.   However that seems
overkill at this time and generating an HTML test matrix
as part of the build seems reasonable.

I did spend some time writing an Ant build file, but was running
into a problem with either Ant or Xalan using the wrong base for
resolving external entity references causing schema generation to fail.



