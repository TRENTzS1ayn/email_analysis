docno="lists-101-15954836"
received="Fri Mar 12 11:26:20 2004"
isoreceived="20040312162620"
sent="Fri, 12 Mar 2004 16:25:39 +0000"
isosent="20040312162539"
name="Jeremy Carroll"
email="jjc@hplb.hpl.hp.com"
subject="Re: Test suite validity"
id="4051E483.2030906@hplb.hpl.hp.com"
charset="us-ascii"
inreplyto="009601c40838$d7893220$6400a8c0&#64;sdct.nist.gov"
expires="-1"


To: Mary Brady<mbrady@nist.gov>
Cc: Ian Hickson<ian@hixie.ch>,www-qa@w3.org,www-dom-ts@w3.org, Tantek ?elik<tantek@cs.stanford.edu>,dom@w3.org,wchang@nist.gov,tmichel@w3.org,mary.brady@nist.gov,bradp@microsoft.com




Mary Brady wrote:

> Many of the complexities of the test harness stem from dealing with other
> technologies, and how each implementation deals with
> them.


I felt that Ian's talk over-emphasized testing just one technology at a 
time. If the problems occur in using two or three technologies or two or 
three specifications together then test suites should cover those cases. 
This is particularly important where it is not clear which spec covers the 
area since we can get implementorA saying "reading spec A we do it this 
way", and implementorB sayig "reading spec B we do it this other way".

I think a test case is a good way of banging the heads of WG-A and WG-B 
together

(While I have phrased this in my issue-driven mindset, I think the point is 
good for conformance testing too - the goal is interoperable 
implementations in that case)



Jeremy



