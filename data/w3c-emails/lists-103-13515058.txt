docno="lists-103-13515058"
received="Fri Jun 22 14:11:57 2001"
isoreceived="20010622181157"
sent="Fri, 22 Jun 2001 08:05:17 -0400 (EDT)"
isosent="20010622120517"
name="Christian Nentwich"
email="c.nentwich@cs.ucl.ac.uk"
subject="Re: Document Object Model (DOM) Level 3 XPath Specification"
id="01062213043100.01070@wasabi.cs.ucl.ac.uk"
charset="iso-8859-1"
inreplyto="3B3275B8.60401&#64;netscape.com"
expires="-1"

To:rayw@netscape.com(Ray Whitmer), Philippe Le Hegaret<plh@w3.org>,bradford@dbxmlgroup.com
Cc:www-dom@w3.org



> >>I have further requirements that require the repeated evaluation of
> >> XPaths (>= 100000 times). I find the Xalan approach quite useful here,
> >> which parses the path once to be evaluated multiple times. I see quite a
> >> bad performance hit coming along if I use the interfaces from the draft
> Either of these cases can be improved in the implementation by very
> simple caching schemes:

I agree completely. However, 100000 hash table lookups take longer than 0 
hashtable lookups. More importantly, the application programmer will
know a lot better when a parsed path object is not needed anymore. I would 
like to be able to control this behaviour, not have it hidden behind the 
interface. I can already see myself editing the processor source code because 
it discards my objects too frequently :) One size does not fit all...

As for moving these features into the query working group, I have no real 
interest in pluging additional bulky packages into my code just to achieve 
something as simple as reusing parsed path expressions..

Christian

Christian Nentwich
Dept. of Computer Science, University College London
+44 (0)20 7679 7190 - http://www.cs.ucl.ac.uk/staff/c.nentwich



